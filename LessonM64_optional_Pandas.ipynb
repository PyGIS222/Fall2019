{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PyGIS222/Fall2019/blob/master/LessonM64_optional_Pandas.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Lesson 6.4 (optional)\n",
    "\n",
    "# Pandas\n",
    "\n",
    "This Jupyter Notebook is part of Module 6 of the course GIS222 (Fall2019). This lesson discusses the Python Module **Pandas**. Carefully study the content of this Notebook and use the chance to reflect the material through the interactive examples.\n",
    "\n",
    "Learning goals of this lesson notebook and the following problem notebook are:\n",
    "\n",
    "* Read data from a .csv text file into Python using Pandas\n",
    "* Do simple data analysis using Pandas data structures and related functions\n",
    "* Write data from Pandas to a .csv text file\n",
    "\n",
    "Note: The content of this notebook and the related problem file is congruent to the material for the module numpy from the course module 4, however, we are discussing how to perform the same data import, analysis and export steps with the Pandas module.\n",
    "\n",
    "### Related Video Tutorials\n",
    "\n",
    "Part A and B of this notebook are adapted from the Geo-Python Pandas lesson, which offers also two related video tutorials. Watching these tutorial is not mandatory for GIS222 and we do not assume any responsibility for the content or its quality. But they might be helpful for some. You might have to skip over parts that were not adapted or only relevant at the time of recording. \n",
    "* [Video for Part A: Exploring Data Using Pandas](https://youtu.be/ChBmDtYHEXk) \n",
    "* [Video for Part B: Processing Data with Pandas](https://youtu.be/76Q73sbiw7I) \n",
    "\n",
    "### Sources\n",
    "These lessons are an adaption of the Pandas lesson from [Geo-Python 2018](https://geo-python.github.io/site/2018/lessons/L5/pandas.html), which is licensed under a Creative Commons Attribution-ShareAlike 4.0 International licence.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/M64_Pandas.png\" width=\"600\" />\n",
    "\n",
    "#  What is Pandas?\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) is a modern and feature rich data analysis framework for Python that is designed to make data analysis and manipulation straightforward and powerful using easy-to-use data structures and operations. It is a mature data analytics framework that is widely used among different fields of science, thus there exists a lot of good examples and documentation that can help you get going with your data analysis tasks.\n",
    "Pandas offspring **GeoPandas** is widely used in GIS data anlysis problems. \n",
    "\n",
    "## Easy-to-use data structures\n",
    "\n",
    "In Pandas the data is typically stored into a **DataFrame** that looks like a typical table with rows and columns (marked with indices and column names). The columns can contain data of different data types. Thus, the way data is stored looks similar to Excel sheets.\n",
    "\n",
    "## Combines functionalities from many Python modules\n",
    "\n",
    "Pandas takes advantage of the [numpy](http://www.numpy.org/)-module which runs under the hood and is mostly written in C, which makes it fast and powerful library that can handle large datasets. However, Pandas offers a more intuitive syntax. However, Pandas is much more than easier-to-use numpy as it also combines many functionalities from other Python libraries such as [matplotlib](https://matplotlib.org/) (plotting) and [scipy](https://www.scipy.org/) (mathematics, science, engineering). Thus, you can use many features included in those packages without importing them.\n",
    "\n",
    "## Supports data reading & writing for a variety of formats\n",
    "\n",
    "One of the most useful features of Pandas is its ability to read data from numerous different data formats directly. For example, Pandas supports reading and writing data from/to:\n",
    "\n",
    "* CSV\n",
    "* JSON\n",
    "* HTML\n",
    "* MS Excel\n",
    "* HDF5\n",
    "* Stata\n",
    "* SAS\n",
    "* Python Pickle format\n",
    "* SQL (Postgresql, MySQL, Oracle, MariaDB, etc.)\n",
    "\n",
    "See a full list from [Pandas' documentation pages](http://pandas.pydata.org/pandas-docs/version/0.20/io.html). Then let's look into the details of what Pandas offers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Exploring Data Using Pandas\n",
    "\n",
    "We begin with learning how to read and explore data files using Pandas. We will continue to explore the Finnland weather data (some information on that below), to get familiar with Pandas data structures: **Series** and **DataFrame**. \n",
    "\n",
    "Pandas **DataFrame** (a 2-dimensional data structure) is used for storing and mainpulating table-like data (data with rows and columns) in Python. You can think of Pandas DataFrame as an attribute table (an excel-like spreadsheet, but much better!). Pandas Series (a 1-dimensional data structure) is used for storing and manipulating a sequence of values. Pandas DataFrames are very easy to access, because they combine the sequential features of lists with mapping features of dictionaries in one object type.\n",
    "\n",
    "Pandas **Series** is similar to a list, but more clever. One row or one column in a Pandas DataFrame is actually a Pandas Series. \n",
    "\n",
    "For a comprehensive overview of pandas data structures, you can have a look at Wes MacKinney’s book [Python for Data Analysis (2nd Edition, 2017) on GitHub](https://github.com/wesm/pydata-book) and [Pandas online documentation](https://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html) about data structures.\n",
    "\n",
    "Reading data files using Pandas will make life a bit easier compared to the traditional Python way of reading data files, similar to the options in the NumPy module.\n",
    "\n",
    "\n",
    "## The data\n",
    "\n",
    "The data we will be working with are weather observations stored in the text file `Kumpula-June-2016-w-metadata.txt` (in the subdirectory `data`), which we have already been using in the course module 4. The data file is a 30-lines cutout of data downloaded from the climate data base of the [National Oceanographic and Atmospheric Administration](https://www.ncdc.noaa.gov/cdo-web/) (NOAA). It contains observed daily mean, minimum, and maximum temperatures from June 2016 recorded from the Kumpula weather observation station in Helsinki. Have a look into the file, before working with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a data file with Pandas\n",
    "\n",
    "Now we’re ready to read in our temperature data file. But first, we need to import the Pandas module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is ready to use now. Take note that we imported the Pandas module with the acronym `pd`. \n",
    "\n",
    "**Now we’ll read the file data into a variable called ``dataFrame``**. Using the function `pandas.read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file using pandas\n",
    "dataFrame = pd.read_csv('./data/Kumpula-June-2016-w-metadata.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas `pd.read_csv()` is a general function for reading data files separated by commas, spaces, or other common separators. For a full list of parameters for this function, please refer to [pandas documentation page for pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).\n",
    "\n",
    "To use the function, we pass simply the filename as input parameter. You should now have a new variable defined as `dataFrame` in the memory, which stored the content of the file. You can check that by typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       # Data file contents: Daily temperatures (mean            min  \\\n",
      "0                 #                     for June 1-30           2016   \n",
      "1   # Data source: https://www.ncdc.noaa.gov/cdo-w...            NaN   \n",
      "2   # Data processing: Extracted temperatures from...   converted to   \n",
      "3           #                  comma-separated format            NaN   \n",
      "4                                                   #            NaN   \n",
      "5                          # David Whipp - 02.10.2017            NaN   \n",
      "6                                            YEARMODA           TEMP   \n",
      "7                                            20160601           65.5   \n",
      "8                                            20160602           65.8   \n",
      "9                                            20160603           68.4   \n",
      "10                                           20160604           57.5   \n",
      "11                                           20160605           51.4   \n",
      "12                                           20160606           52.2   \n",
      "13                                           20160607           56.9   \n",
      "14                                           20160608           54.2   \n",
      "15                                           20160609           49.4   \n",
      "16                                           20160610           49.5   \n",
      "17                                           20160611           54.0   \n",
      "18                                           20160612           55.4   \n",
      "19                                           20160613           58.3   \n",
      "20                                           20160614           59.7   \n",
      "21                                           20160615           63.4   \n",
      "22                                           20160616           57.8   \n",
      "23                                           20160617           60.4   \n",
      "24                                           20160618           57.3   \n",
      "25                                           20160619           56.3   \n",
      "26                                           20160620           59.3   \n",
      "27                                           20160621           62.6   \n",
      "28                                           20160622           61.7   \n",
      "29                                           20160623           60.9   \n",
      "30                                           20160624           61.1   \n",
      "31                                           20160625           65.7   \n",
      "32                                           20160626           69.6   \n",
      "33                                           20160627           60.7   \n",
      "34                                           20160628           65.4   \n",
      "35                                           20160629           65.8   \n",
      "36                                           20160630           65.7   \n",
      "\n",
      "    max) for Kumpula  Helsinki  \n",
      "0                NaN       NaN  \n",
      "1                NaN       NaN  \n",
      "2                NaN       NaN  \n",
      "3                NaN       NaN  \n",
      "4                NaN       NaN  \n",
      "5                NaN       NaN  \n",
      "6                MAX       MIN  \n",
      "7               73.6      54.7  \n",
      "8               80.8      55.0  \n",
      "9               77.9      55.6  \n",
      "10              70.9      47.3  \n",
      "11              58.3      43.2  \n",
      "12              59.7      42.8  \n",
      "13              65.1      45.9  \n",
      "14              60.4      47.5  \n",
      "15              54.1      45.7  \n",
      "16              55.9      43.0  \n",
      "17              62.1      41.7  \n",
      "18              64.2      46.0  \n",
      "19              68.2      47.3  \n",
      "20              67.8      47.8  \n",
      "21              70.3      49.3  \n",
      "22              67.5      55.6  \n",
      "23              70.7      55.9  \n",
      "24              62.8      54.0  \n",
      "25              59.2      54.1  \n",
      "26              69.1      52.2  \n",
      "27              71.4      50.4  \n",
      "28              70.2      55.4  \n",
      "29              67.1      54.9  \n",
      "30              68.9      56.7  \n",
      "31              75.4      57.9  \n",
      "32              77.7      60.3  \n",
      "33              70.0      57.6  \n",
      "34              73.0      55.8  \n",
      "35              73.2      59.7  \n",
      "36              72.7      59.2  \n"
     ]
    }
   ],
   "source": [
    "print(dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks OK, but there `NaN` values present. `NaN` stands for \"not a number\", and might indicate that there were some problems when reading the file. \n",
    "\n",
    "In addition, the first lines of the dataframe store metadata (from the header of the file), not data. We expected about 30 lines of data, but the index values count up to 36 when we print the content of the `dataFrame` variable to screen. It looks like we need to investigate this further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata at the top of the file provide some basic information about the file content and its source. This isn't data we want to process, so we need to skip over that part of the file when we load it.\n",
    "\n",
    "Here are the first eigth rows of data in the text file (note that the 8th row is blank):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Data file contents: Daily temperatures (mean, min, max) for Kumpula, Helsinki\n",
    "#                     for June 1-30, 2016\n",
    "# Data source: https://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND\n",
    "# Data processing: Extracted temperatures from raw data file, converted to\n",
    "#                  comma-separated format\n",
    "#\n",
    "# David Whipp - 02.10.2017\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skipping over the header is easy to implement in Pandas, we just **add the `skiprows` parameter when we read the file, listing the number of rows to skip (8 in this case).**\n",
    "\n",
    "Let's read the datafile again, this time defining the `skiprows` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = pd.read_csv('./data/Kumpula-June-2016-w-metadata.txt', skiprows=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now print the rows and see what changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEARMODA  TEMP   MAX   MIN\n",
      "0   20160601  65.5  73.6  54.7\n",
      "1   20160602  65.8  80.8  55.0\n",
      "2   20160603  68.4  77.9  55.6\n",
      "3   20160604  57.5  70.9  47.3\n",
      "4   20160605  51.4  58.3  43.2\n",
      "5   20160606  52.2  59.7  42.8\n",
      "6   20160607  56.9  65.1  45.9\n",
      "7   20160608  54.2  60.4  47.5\n",
      "8   20160609  49.4  54.1  45.7\n",
      "9   20160610  49.5  55.9  43.0\n",
      "10  20160611  54.0  62.1  41.7\n",
      "11  20160612  55.4  64.2  46.0\n",
      "12  20160613  58.3  68.2  47.3\n",
      "13  20160614  59.7  67.8  47.8\n",
      "14  20160615  63.4  70.3  49.3\n",
      "15  20160616  57.8  67.5  55.6\n",
      "16  20160617  60.4  70.7  55.9\n",
      "17  20160618  57.3  62.8  54.0\n",
      "18  20160619  56.3  59.2  54.1\n",
      "19  20160620  59.3  69.1  52.2\n",
      "20  20160621  62.6  71.4  50.4\n",
      "21  20160622  61.7  70.2  55.4\n",
      "22  20160623  60.9  67.1  54.9\n",
      "23  20160624  61.1  68.9  56.7\n",
      "24  20160625  65.7  75.4  57.9\n",
      "25  20160626  69.6  77.7  60.3\n",
      "26  20160627  60.7  70.0  57.6\n",
      "27  20160628  65.4  73.0  55.8\n",
      "28  20160629  65.8  73.2  59.7\n",
      "29  20160630  65.7  72.7  59.2\n"
     ]
    }
   ],
   "source": [
    "print(dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks more like it.\n",
    "\n",
    "But, why did the dataframe look so weird before we skipped the first rows? \n",
    "\n",
    "The file data was read into a Pandas **DataFrame**, which is  a two-dimensional structure used for storing table-like data. A pandas dataframe contains a collection of columns. And each column can be of different data type (string, float, int, boolean, etc.).\n",
    "\n",
    "In our first attempt to read data from the text file, the first rows containing metadata did not belong to the actual data array, which caused the automatic data structure detection of the `read_csv()` function to fail. **Indeed, the `read_csv`-function expects column names in the first line of the file, by default.** For other options to skip the header, study the parameter `header` in the [read_csv documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).\n",
    "\n",
    "**What would happen if we skipped 9 rows? (try it out!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your trial here, but make sure to re-run the correct command after this trial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataFrames are so useful, because they come with labelled axes (rows and columns).  For our example above, the rows were labeled with an index value (`0` to `29`), and the columns were labelled `YEARMODA`, `TEMP`, `MAX`, and `MIN`. Now we can easily use these labels to divide up our data and make interacting with it easier as you'll see later in the lesson.\n",
    "\n",
    "The mistake we made above (trying to read a datafile with some header text) is *very* common. Therefore, **it always helps to first get a sense of what the datafile looks like before you try to read it**. \n",
    "\n",
    "After reading in the data, make sure to check that everything went well (for example with the print-statement). Another challenge may be that large datafiles might not nicely print on screen using the `print()`-function. In this case, request only the top 5-10 lines of the file. \n",
    "\n",
    "**To check the contents of the dataframe, we can  use `pandas.DataFrame.head`-function.** This function returns the first n rows for the dataframe. By default, it returns the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEARMODA</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20160601</td>\n",
       "      <td>65.5</td>\n",
       "      <td>73.6</td>\n",
       "      <td>54.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20160602</td>\n",
       "      <td>65.8</td>\n",
       "      <td>80.8</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20160603</td>\n",
       "      <td>68.4</td>\n",
       "      <td>77.9</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20160604</td>\n",
       "      <td>57.5</td>\n",
       "      <td>70.9</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20160605</td>\n",
       "      <td>51.4</td>\n",
       "      <td>58.3</td>\n",
       "      <td>43.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEARMODA  TEMP   MAX   MIN\n",
       "0  20160601  65.5  73.6  54.7\n",
       "1  20160602  65.8  80.8  55.0\n",
       "2  20160603  68.4  77.9  55.6\n",
       "3  20160604  57.5  70.9  47.3\n",
       "4  20160605  51.4  58.3  43.2"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the tail of the dataset instead, use the function `tail()`. Now we can move on to exploring our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring our dataset: DataFrames and Series\n",
    "\n",
    "A usual first step, when using new data, is to explore the dataset and getting to know its structure as well as what kind of values are stored in it.\n",
    "\n",
    "**Let's look at the columns we have in our DataFrame.** We can receive this information requesting the built-in attribute `columns` of the DataFrame object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['YEARMODA', 'TEMP', 'MAX', 'MIN'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Print columns\n",
    "print(dataFrame.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you see the names of the columns in the datafile.\n",
    "\n",
    "In addition, we can also **find information about the rows in the datafile using the ``index`` attribute**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=30, step=1)\n"
     ]
    }
   ],
   "source": [
    "#Print index\n",
    "print(dataFrame.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows, how the data is indexed: Starting at 0, ending at 30, and an increment of 1 between each index value. This is basically the same way in which Python lists are indexed, which suggests there are other ways to identify the rows in data using Pandas.\n",
    "   \n",
    "We'll see a bit more about this later. For now, if you want to know **how many rows your data set has, you can use also ``len()`` function**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# Print number of rows using len()-function\n",
    "# print(len(dataFrame.index))\n",
    "print(len(dataFrame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also request the size of the dataset with the ``shape`` attribute**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 4)\n"
     ]
    }
   ],
   "source": [
    "# Print dataframe shape\n",
    "print(dataFrame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has 30 rows, 4 columns, exaclty as we know from above.\n",
    "\n",
    "Now we want to investigate the **type data** we have in our DataFrame. Let's first request the object type of `dataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data type of the dataFrame variable\n",
    "type(dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No surprises here, our Pandas variable `DataFrame` is a Pandas **DataFrame** 😉.\n",
    "\n",
    "The IPython magic command `%who` is also useful to get such information about the DataFrame variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable            Type           Data/Info\n",
      "--------------------------------------------\n",
      "dataFrame           DataFrame          YEARMODA  TEMP   MAX <...>0160630  65.7  72.7  59.2\n",
      "excel_output_fp     str            Kumpula_temps_above15_June_2016.xlsx\n",
      "fp                  str            ./data/Kumpula-June-2016-w-metadata.txt\n",
      "func                function       <function func at 0x117cefe60>\n",
      "li                  list           n=0\n",
      "li2                 list           n=0\n",
      "list                list           n=3\n",
      "myDataFrame         DataFrame         number\\n0     1.0\\n1  <...>5.0\\n5     6.0\\n6     7.0\n",
      "myList              list           n=7\n",
      "mySeries            Series         0    1.0\\n1    2.0\\n2    <...>n6    7.0\\ndtype: float64\n",
      "numpy               module         <module 'numpy' from '/an<...>kages/numpy/__init__.py'>\n",
      "output_fp           str            Kumpula_temps_June_2016.csv\n",
      "output_fp2          str            Kumpula_temps_above15_June_2016.csv\n",
      "pd                  module         <module 'pandas' from '/a<...>ages/pandas/__init__.py'>\n",
      "row8                Series         YEARMODA        2.016061e<...>\\nName: 8, dtype: float64\n",
      "rows5               DataFrame         YEARMODA  TEMP   MAX  <...>1       8.2     10.777778\n",
      "sorted_temp_a       DataFrame          YEARMODA  TEMP   MAX <...>4       9.3     20.888889\n",
      "sorted_temp_d       DataFrame          YEARMODA  TEMP   MAX <...>9.666667             10.0\n",
      "temps_5to10         DataFrame          TEMP  TEMP_Celsius\\n5<...>2\\n10  54.0     12.222222\n",
      "temps_only          DataFrame          TEMP  TEMP_Celsius\\n0<...>8\\n29  65.7     18.722222\n",
      "uniq_temp_days      int            11\n",
      "unique              ndarray        11: 11 elems, type `float64`, 88 bytes\n",
      "w_temps             DataFrame          YEARMODA  TEMP   MAX <...>5       6.5     18.722222\n",
      "w_temps2            DataFrame          YEARMODA  TEMP   MAX <...>5       6.5     18.722222\n",
      "w_temps_clean       DataFrame          YEARMODA  TEMP   MAX <...>5       6.5     18.722222\n",
      "w_temps_na_filled   DataFrame          YEARMODA  TEMP   MAX <...>5       6.5     18.722222\n",
      "writer              _XlsxWriter    <pandas.io.excel._xlsxwri<...>er object at 0x117e5f310>\n"
     ]
    }
   ],
   "source": [
    "# Display variable name, type and info\n",
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look into the types of data in the columns of the `dataFrame` variable. The attribute **dtypes** helps to find that out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEARMODA      int64\n",
      "TEMP        float64\n",
      "MAX         float64\n",
      "MIN         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print data types\n",
    "print(dataFrame.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``dtypes`` attribute holds the data types for each column.\n",
    "For our example, we see that ``YEARMODA`` is an integer value (with 64-bit precision; int64), while all other values are decimal values with 64-bit precision (float64).\n",
    "\n",
    "In addition, we can also **select a single column of `dataFrame` by referencing it with the name of that column**. And printing out the values of a column, shows not only the values, but also their data type, at the bottom of the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     65.5\n",
      "1     65.8\n",
      "2     68.4\n",
      "3     57.5\n",
      "4     51.4\n",
      "5     52.2\n",
      "6     56.9\n",
      "7     54.2\n",
      "8     49.4\n",
      "9     49.5\n",
      "10    54.0\n",
      "11    55.4\n",
      "12    58.3\n",
      "13    59.7\n",
      "14    63.4\n",
      "15    57.8\n",
      "16    60.4\n",
      "17    57.3\n",
      "18    56.3\n",
      "19    59.3\n",
      "20    62.6\n",
      "21    61.7\n",
      "22    60.9\n",
      "23    61.1\n",
      "24    65.7\n",
      "25    69.6\n",
      "26    60.7\n",
      "27    65.4\n",
      "28    65.8\n",
      "29    65.7\n",
      "Name: TEMP, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Print out a single column\n",
    "print(dataFrame['TEMP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, the **entire column itself has its own object type**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check datatype of that column\n",
    "type(dataFrame['TEMP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Pandas **Series**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So while the items in the DataFrame column are of float64 data type, an entire column of a DataFrame is called a *Series* in Pandas. Let's briefly discuss how you can create a Pandas Series from a Python list (and further convert it into a Pandas DataFrame). \n",
    "\n",
    "If you have long lists of numbers, you can convert them into a Pandas Series, which will allow you to interact with these values more efficiently (in terms of computation times). \n",
    "\n",
    "For example, a list **``myList`` is converted to a Pandas Series using the ``ps.Series()`` function**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    2.0\n",
      "2    3.0\n",
      "3    4.0\n",
      "4    5.0\n",
      "5    6.0\n",
      "6    7.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create Pandas Series from a list\n",
    "myList = [1, 2, 3, 4, 5, 6, 7.0]\n",
    "mySeries = pd.Series(myList)\n",
    "print(mySeries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, note that Pandas is smart about the conversion: it detects a single floating point value (``7.0``) and then assigns the data type float64 to all values in the Series.\n",
    "\n",
    "We could also **convert the Pandas Series into a Pandas DataFrame** by initiating a new [pandas.DataFrame()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Check data type of the input\n",
    "print(type(mySeries))\n",
    "\n",
    "# Create a pandas dataframe\n",
    "myDataFrame = pd.DataFrame(mySeries)\n",
    "\n",
    "#Check the data type\n",
    "print(type(myDataFrame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "0  1.0\n",
      "1  2.0\n",
      "2  3.0\n",
      "3  4.0\n",
      "4  5.0\n",
      "5  6.0\n",
      "6  7.0\n"
     ]
    }
   ],
   "source": [
    "print(myDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li=[]\n",
    "\n",
    "def func(li2):\n",
    "    for e in li2:\n",
    "        li.append(2*e)\n",
    "    return(li)\n",
    "\n",
    "li2=[]\n",
    "func(li2)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we have a pandas dataframe with one column of data, and an associated index. By default, the column name (label) has been set to '0'. We can **give the column a new name** applying the foolowing syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   number\n",
      "0     1.0\n",
      "1     2.0\n",
      "2     3.0\n",
      "3     4.0\n",
      "4     5.0\n",
      "5     6.0\n",
      "6     7.0\n"
     ]
    }
   ],
   "source": [
    "# Rename the first column\n",
    "myDataFrame.columns = [\"number\"]\n",
    "print(myDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's continue with our original DataFrame `dataFrame`.\n",
    "\n",
    "## Common Methods for DataFrames and Series\n",
    "\n",
    "Just like DataFrames, Pandas Series have a set of attributes and methods, which support fast access to and processing of the data.\n",
    "\n",
    "**Useful methods include `mean()`, `median()`, `min()`, `max()`, and `std()`** (the standard deviation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that we don't need to store `dataFrame['TEMP']` into a separate series variable in order to apply the `mean()` method.\n",
    "\n",
    "Another useful function is the **``describe()`` function, which provides an overview of the basic statistics for all attributes in your DataFrame**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.73"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check mean value of a column\n",
    "dataFrame['TEMP'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEARMODA</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2.016062e+07</td>\n",
       "      <td>59.730000</td>\n",
       "      <td>67.940000</td>\n",
       "      <td>51.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>8.803408e+00</td>\n",
       "      <td>5.475472</td>\n",
       "      <td>6.651761</td>\n",
       "      <td>5.634484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>2.016060e+07</td>\n",
       "      <td>49.400000</td>\n",
       "      <td>54.100000</td>\n",
       "      <td>41.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2.016061e+07</td>\n",
       "      <td>56.450000</td>\n",
       "      <td>63.150000</td>\n",
       "      <td>47.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>2.016062e+07</td>\n",
       "      <td>60.050000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>54.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>2.016062e+07</td>\n",
       "      <td>64.900000</td>\n",
       "      <td>72.375000</td>\n",
       "      <td>55.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2.016063e+07</td>\n",
       "      <td>69.600000</td>\n",
       "      <td>80.800000</td>\n",
       "      <td>60.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           YEARMODA       TEMP        MAX        MIN\n",
       "count  3.000000e+01  30.000000  30.000000  30.000000\n",
       "mean   2.016062e+07  59.730000  67.940000  51.750000\n",
       "std    8.803408e+00   5.475472   6.651761   5.634484\n",
       "min    2.016060e+07  49.400000  54.100000  41.700000\n",
       "25%    2.016061e+07  56.450000  63.150000  47.300000\n",
       "50%    2.016062e+07  60.050000  69.000000  54.050000\n",
       "75%    2.016062e+07  64.900000  72.375000  55.750000\n",
       "max    2.016063e+07  69.600000  80.800000  60.300000"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get descriptive statistics\n",
    "dataFrame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, **Series allow for type conversions**. For example, if you're planning to print a large number of values to the screen, it might be helpful to transfer those values to character strings. You can achieve such a **type conversions with the `astype()` method** (congruent to NumPy's `astype()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     65.5\n",
      "1     65.8\n",
      "2     68.4\n",
      "3     57.5\n",
      "4     51.4\n",
      "5     52.2\n",
      "6     56.9\n",
      "7     54.2\n",
      "8     49.4\n",
      "9     49.5\n",
      "10    54.0\n",
      "11    55.4\n",
      "12    58.3\n",
      "13    59.7\n",
      "14    63.4\n",
      "15    57.8\n",
      "16    60.4\n",
      "17    57.3\n",
      "18    56.3\n",
      "19    59.3\n",
      "20    62.6\n",
      "21    61.7\n",
      "22    60.9\n",
      "23    61.1\n",
      "24    65.7\n",
      "25    69.6\n",
      "26    60.7\n",
      "27    65.4\n",
      "28    65.8\n",
      "29    65.7\n",
      "Name: TEMP, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Convert temperature values to string\n",
    "print(dataFrame['TEMP'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After convertion, the data type `object` indicates that the temperature values were converted to character strings. A more obvious result is given, when converting them to integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     65\n",
      "1     65\n",
      "2     68\n",
      "3     57\n",
      "4     51\n",
      "5     52\n",
      "6     56\n",
      "7     54\n",
      "8     49\n",
      "9     49\n",
      "10    54\n",
      "11    55\n",
      "12    58\n",
      "13    59\n",
      "14    63\n",
      "15    57\n",
      "16    60\n",
      "17    57\n",
      "18    56\n",
      "19    59\n",
      "20    62\n",
      "21    61\n",
      "22    60\n",
      "23    61\n",
      "24    65\n",
      "25    69\n",
      "26    60\n",
      "27    65\n",
      "28    65\n",
      "29    65\n",
      "Name: TEMP, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the output\n",
    "print(dataFrame['TEMP'].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temperature values were cut off to integer numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Note:**\n",
    "\n",
    "Be careful with type conversions from floating point values to integers. The conversion simply truncates the numbers at the decimal point. Hence, so all values are rounded down. For example, 99.99 will be rounded to 99.\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "It might be good to round the values before converting them to integers. You can **chain the `round()` and `type()` functions together**. The **command chain `.round(0).astype(int)`**, first rounds the values with zero decimals and then it converts those values into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated values:\n",
      "0    65\n",
      "1    65\n",
      "2    68\n",
      "3    57\n",
      "4    51\n",
      "Name: TEMP, dtype: int64\n",
      "\n",
      "\n",
      "Rounded values:\n",
      "0    66\n",
      "1    66\n",
      "2    68\n",
      "3    58\n",
      "4    51\n",
      "Name: TEMP, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Integer, truncated:\n",
    "print(\"Truncated values:\")\n",
    "print(dataFrame['TEMP'].astype(int).head())\n",
    "\n",
    "# Add empty line:\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Rounded values:\")\n",
    "#Integer, rounded:\n",
    "print(dataFrame['TEMP'].round(0).astype(int).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we stop our exploration, and we would like to continue with data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# B. Processing Data with Pandas\n",
    "\n",
    "After discussin the basics of Pandas data structures **DataFrames** and **Series**, we will continue to explore available operations for data analysis.\n",
    "\n",
    "Let's first read the same data as before into a Pandas DataFrame to have a clean start. Then we will focus on a few new aspects of importing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fp = r'./data/Kumpula-June-2016-w-metadata.txt'\n",
    "dataFrame = pd.read_csv(fp, sep=',', skiprows=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note two things in the code above:\n",
    "\n",
    "- **'r' prefix** in front of the filepath string. \n",
    "- **`sep=','`** parameter in the `read_csv()` function defines a delimiter. \n",
    "\n",
    "In our case, both of these details are not needed (the code works correctly without them), but they might come in handy in the future. \n",
    "\n",
    "The letter 'r' makes sure that the filepath is interpreted correctly. Without the 'r', backslashes are treated as escape characters. With the r, backslashes are treated as literal. This becomes relevant, if you define full filepaths with the filename on a windows computer.\n",
    "\n",
    "The **default delimiter in the `read_csv()` function is a comma (`,`)**. The example shows, how you could also define other characers and expressions as delimiter. In our case, however, the correct delimiter is a comma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing with DataFrames\n",
    "\n",
    "One of the most common things performed with Pandas objects, is to **create new columns based on calculations between other variables (columns)**.\n",
    "\n",
    "We can create a new column into our DataFrame, by specifying the name of the column and giving it some default value. In an example below, we create a new **column** `'DIFF'` and specify a decimal number 0.0 as default value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEARMODA  TEMP   MAX   MIN  DIFF\n",
      "0   20160601  65.5  73.6  54.7   0.0\n",
      "1   20160602  65.8  80.8  55.0   0.0\n",
      "2   20160603  68.4  77.9  55.6   0.0\n",
      "3   20160604  57.5  70.9  47.3   0.0\n",
      "4   20160605  51.4  58.3  43.2   0.0\n",
      "5   20160606  52.2  59.7  42.8   0.0\n",
      "6   20160607  56.9  65.1  45.9   0.0\n",
      "7   20160608  54.2  60.4  47.5   0.0\n",
      "8   20160609  49.4  54.1  45.7   0.0\n",
      "9   20160610  49.5  55.9  43.0   0.0\n",
      "10  20160611  54.0  62.1  41.7   0.0\n",
      "11  20160612  55.4  64.2  46.0   0.0\n",
      "12  20160613  58.3  68.2  47.3   0.0\n",
      "13  20160614  59.7  67.8  47.8   0.0\n",
      "14  20160615  63.4  70.3  49.3   0.0\n",
      "15  20160616  57.8  67.5  55.6   0.0\n",
      "16  20160617  60.4  70.7  55.9   0.0\n",
      "17  20160618  57.3  62.8  54.0   0.0\n",
      "18  20160619  56.3  59.2  54.1   0.0\n",
      "19  20160620  59.3  69.1  52.2   0.0\n",
      "20  20160621  62.6  71.4  50.4   0.0\n",
      "21  20160622  61.7  70.2  55.4   0.0\n",
      "22  20160623  60.9  67.1  54.9   0.0\n",
      "23  20160624  61.1  68.9  56.7   0.0\n",
      "24  20160625  65.7  75.4  57.9   0.0\n",
      "25  20160626  69.6  77.7  60.3   0.0\n",
      "26  20160627  60.7  70.0  57.6   0.0\n",
      "27  20160628  65.4  73.0  55.8   0.0\n",
      "28  20160629  65.8  73.2  59.7   0.0\n",
      "29  20160630  65.7  72.7  59.2   0.0\n"
     ]
    }
   ],
   "source": [
    "# Define a new column \"DIFF\"\n",
    "dataFrame['DIFF'] = 0.0\n",
    "\n",
    "# Print the dataframe\n",
    "print(dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check the datatype of the new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check datatypes\n",
    "dataFrame['DIFF'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, Pandas created a new column and automatically recognized that the data if of type float.\n",
    "\n",
    "In addition, we can **perform calculations with the columns in the DataFrame**. Let's update the column ``DIFF`` by calculating the difference between the ``MAX`` and ``MIN`` columns. This will give insight into how much the temperatures have been varying during different days. \n",
    "\n",
    "Calculations can be done with the following syntax. First, we specify the column we want to update (i.e. ``DIFF``) and then we add the actual calculation by entering the names of the columns in our dataFrameFrame, accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEARMODA  TEMP   MAX   MIN  DIFF\n",
      "0   20160601  65.5  73.6  54.7  18.9\n",
      "1   20160602  65.8  80.8  55.0  25.8\n",
      "2   20160603  68.4  77.9  55.6  22.3\n",
      "3   20160604  57.5  70.9  47.3  23.6\n",
      "4   20160605  51.4  58.3  43.2  15.1\n",
      "5   20160606  52.2  59.7  42.8  16.9\n",
      "6   20160607  56.9  65.1  45.9  19.2\n",
      "7   20160608  54.2  60.4  47.5  12.9\n",
      "8   20160609  49.4  54.1  45.7   8.4\n",
      "9   20160610  49.5  55.9  43.0  12.9\n",
      "10  20160611  54.0  62.1  41.7  20.4\n",
      "11  20160612  55.4  64.2  46.0  18.2\n",
      "12  20160613  58.3  68.2  47.3  20.9\n",
      "13  20160614  59.7  67.8  47.8  20.0\n",
      "14  20160615  63.4  70.3  49.3  21.0\n",
      "15  20160616  57.8  67.5  55.6  11.9\n",
      "16  20160617  60.4  70.7  55.9  14.8\n",
      "17  20160618  57.3  62.8  54.0   8.8\n",
      "18  20160619  56.3  59.2  54.1   5.1\n",
      "19  20160620  59.3  69.1  52.2  16.9\n",
      "20  20160621  62.6  71.4  50.4  21.0\n",
      "21  20160622  61.7  70.2  55.4  14.8\n",
      "22  20160623  60.9  67.1  54.9  12.2\n",
      "23  20160624  61.1  68.9  56.7  12.2\n",
      "24  20160625  65.7  75.4  57.9  17.5\n",
      "25  20160626  69.6  77.7  60.3  17.4\n",
      "26  20160627  60.7  70.0  57.6  12.4\n",
      "27  20160628  65.4  73.0  55.8  17.2\n",
      "28  20160629  65.8  73.2  59.7  13.5\n",
      "29  20160630  65.7  72.7  59.2  13.5\n"
     ]
    }
   ],
   "source": [
    "#Calculate max min difference\n",
    "dataFrame['DIFF'] = dataFrame['MAX'] - dataFrame['MIN']\n",
    "\n",
    "# Print the dataframe\n",
    "print(dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, we can see that he calculations were stored into the ``DIFF`` column. \n",
    "\n",
    "We can code this even more efficiently: we can **create new columns on-the-fly**, hence, together with the calculation. Let's test for a new column. This time we calculate the difference between the minimum temperature (``MIN``) and the mean temperature of each day (``TEMP``):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEARMODA  TEMP   MAX   MIN  DIFF  DIFF_Min\n",
      "0   20160601  65.5  73.6  54.7  18.9      10.8\n",
      "1   20160602  65.8  80.8  55.0  25.8      10.8\n",
      "2   20160603  68.4  77.9  55.6  22.3      12.8\n",
      "3   20160604  57.5  70.9  47.3  23.6      10.2\n",
      "4   20160605  51.4  58.3  43.2  15.1       8.2\n",
      "5   20160606  52.2  59.7  42.8  16.9       9.4\n",
      "6   20160607  56.9  65.1  45.9  19.2      11.0\n",
      "7   20160608  54.2  60.4  47.5  12.9       6.7\n",
      "8   20160609  49.4  54.1  45.7   8.4       3.7\n",
      "9   20160610  49.5  55.9  43.0  12.9       6.5\n",
      "10  20160611  54.0  62.1  41.7  20.4      12.3\n",
      "11  20160612  55.4  64.2  46.0  18.2       9.4\n",
      "12  20160613  58.3  68.2  47.3  20.9      11.0\n",
      "13  20160614  59.7  67.8  47.8  20.0      11.9\n",
      "14  20160615  63.4  70.3  49.3  21.0      14.1\n",
      "15  20160616  57.8  67.5  55.6  11.9       2.2\n",
      "16  20160617  60.4  70.7  55.9  14.8       4.5\n",
      "17  20160618  57.3  62.8  54.0   8.8       3.3\n",
      "18  20160619  56.3  59.2  54.1   5.1       2.2\n",
      "19  20160620  59.3  69.1  52.2  16.9       7.1\n",
      "20  20160621  62.6  71.4  50.4  21.0      12.2\n",
      "21  20160622  61.7  70.2  55.4  14.8       6.3\n",
      "22  20160623  60.9  67.1  54.9  12.2       6.0\n",
      "23  20160624  61.1  68.9  56.7  12.2       4.4\n",
      "24  20160625  65.7  75.4  57.9  17.5       7.8\n",
      "25  20160626  69.6  77.7  60.3  17.4       9.3\n",
      "26  20160627  60.7  70.0  57.6  12.4       3.1\n",
      "27  20160628  65.4  73.0  55.8  17.2       9.6\n",
      "28  20160629  65.8  73.2  59.7  13.5       6.1\n",
      "29  20160630  65.7  72.7  59.2  13.5       6.5\n"
     ]
    }
   ],
   "source": [
    "# Calculate difference between temp and min column values\n",
    "dataFrame['DIFF_Min'] = dataFrame['TEMP'] - dataFrame['MIN']\n",
    "\n",
    "# Print the dataframe\n",
    "print(dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we created a new column and performed the calculation in one statement. Calculations like this can be performed using as many columns and operations (e.g. subtracttion, addition, multiplication, division, exponentiation, etc.) as needed.\n",
    "\n",
    "For example, we can for example convert  Fahrenheit temperatures in ``TEMP`` column into Celsius using the formula we have applied many times before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YEARMODA  TEMP   MAX   MIN  DIFF  DIFF_Min  TEMP_Celsius\n",
      "0  20160601  65.5  73.6  54.7  18.9      10.8     18.611111\n",
      "1  20160602  65.8  80.8  55.0  25.8      10.8     18.777778\n",
      "2  20160603  68.4  77.9  55.6  22.3      12.8     20.222222\n",
      "3  20160604  57.5  70.9  47.3  23.6      10.2     14.166667\n",
      "4  20160605  51.4  58.3  43.2  15.1       8.2     10.777778\n"
     ]
    }
   ],
   "source": [
    "# Create a new column and convert temp fahrenheit to celsius:\n",
    "dataFrame['TEMP_Celsius'] = (dataFrame['TEMP'] - 32) / (9/5)\n",
    "\n",
    "#Check output\n",
    "print(dataFrame.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting data using indices\n",
    "\n",
    "In Pandas, you can also select only specific rows from the DataFrame and apply operations to only those selected rows. However, there are different ways of coding this.\n",
    "\n",
    "For example, you can **select specific rows from your DataFrame via index slicing**, extracting part of the DataFrame. Let's select the first five rows and assign them to a new variable called ``rows5``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YEARMODA  TEMP   MAX   MIN  DIFF  DIFF_Min  TEMP_Celsius\n",
      "0  20160601  65.5  73.6  54.7  18.9      10.8     18.611111\n",
      "1  20160602  65.8  80.8  55.0  25.8      10.8     18.777778\n",
      "2  20160603  68.4  77.9  55.6  22.3      12.8     20.222222\n",
      "3  20160604  57.5  70.9  47.3  23.6      10.2     14.166667\n",
      "4  20160605  51.4  58.3  43.2  15.1       8.2     10.777778\n"
     ]
    }
   ],
   "source": [
    "# Select first five rows of dataframe\n",
    "rows5 = dataFrame[0:5]\n",
    "\n",
    "print(rows5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slicing is done similar to Python lists. One has to sepecify an index range that should be selected inside the square brackets: ``selection = dataFrame[start_index:stop_index]``.\n",
    "\n",
    "You can also **select a single row at a specific position applying the ``.loc[]`` indexing method**. Below, we select all the data values from row 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEARMODA        2.016061e+07\n",
      "TEMP            4.940000e+01\n",
      "MAX             5.410000e+01\n",
      "MIN             4.570000e+01\n",
      "DIFF            8.400000e+00\n",
      "DIFF_Min        3.700000e+00\n",
      "TEMP_Celsius    9.666667e+00\n",
      "Name: 8, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Select one row using index\n",
    "row8 = dataFrame.loc[8]\n",
    "\n",
    "print(row8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``.loc[]`` indexing returns values as a ``pd.Series``. And the indices of the Series become the original column names. From the Series, you can access the value of an individual column by referring to its index or name. Use the following formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.4\n"
     ]
    }
   ],
   "source": [
    "#Print content from the selected row\n",
    "print(row8[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.4\n"
     ]
    }
   ],
   "source": [
    "#Print content from the selected row\n",
    "print(row8['TEMP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to **select multiple rows simultaniously**. Below, only temperature values (``TEMP``) between indices of 5-10 are selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5     52.2\n",
      "6     56.9\n",
      "7     54.2\n",
      "8     49.4\n",
      "9     49.5\n",
      "10    54.0\n",
      "Name: TEMP, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Select temp column values between indices 5 and 10\n",
    "temps_5to10 = dataFrame.loc[5:10, 'TEMP']\n",
    "\n",
    "print(temps_5to10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, it is possible to **select multiple columns and multiple rows**, the former based on a list of column names and the latter based on indices. Here, we select ``TEMP`` and the ``TEMP_Celsius`` columns by passing them as a list (``.loc[start_index:stop_index, list_of_columns]``):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TEMP  TEMP_Celsius\n",
      "5   52.2     11.222222\n",
      "6   56.9     13.833333\n",
      "7   54.2     12.333333\n",
      "8   49.4      9.666667\n",
      "9   49.5      9.722222\n",
      "10  54.0     12.222222\n"
     ]
    }
   ],
   "source": [
    "# Select temp and temp_celsius column values between indices 5 and 10\n",
    "temps_5to10 = dataFrame.loc[5:10, ['TEMP', 'TEMP_Celsius']]\n",
    "\n",
    "print(temps_5to10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, of course, you can also **get all rows from those two selected columns**. This, can be achieved by referencing the `dataFrame` with the same list of column names inside square brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TEMP  TEMP_Celsius\n",
      "0   65.5     18.611111\n",
      "1   65.8     18.777778\n",
      "2   68.4     20.222222\n",
      "3   57.5     14.166667\n",
      "4   51.4     10.777778\n",
      "5   52.2     11.222222\n",
      "6   56.9     13.833333\n",
      "7   54.2     12.333333\n",
      "8   49.4      9.666667\n",
      "9   49.5      9.722222\n",
      "10  54.0     12.222222\n",
      "11  55.4     13.000000\n",
      "12  58.3     14.611111\n",
      "13  59.7     15.388889\n",
      "14  63.4     17.444444\n",
      "15  57.8     14.333333\n",
      "16  60.4     15.777778\n",
      "17  57.3     14.055556\n",
      "18  56.3     13.500000\n",
      "19  59.3     15.166667\n",
      "20  62.6     17.000000\n",
      "21  61.7     16.500000\n",
      "22  60.9     16.055556\n",
      "23  61.1     16.166667\n",
      "24  65.7     18.722222\n",
      "25  69.6     20.888889\n",
      "26  60.7     15.944444\n",
      "27  65.4     18.555556\n",
      "28  65.8     18.777778\n",
      "29  65.7     18.722222\n"
     ]
    }
   ],
   "source": [
    "# Select all rows from temp and temp_celsius columns\n",
    "temps_only = dataFrame[['TEMP', 'TEMP_Celsius']]\n",
    "\n",
    "print(temps_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering and updating data\n",
    "\n",
    "Another very useful feature in Pandas is the ability to **filter and select rows based on a conditional statement**.\n",
    "The following example shows how to select those rows where the Celsius temperature is above 15 degrees and save them into the variable ``w_temps`` (warm temperatures).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEARMODA  TEMP   MAX   MIN  DIFF  DIFF_Min  TEMP_Celsius\n",
      "0   20160601  65.5  73.6  54.7  18.9      10.8     18.611111\n",
      "1   20160602  65.8  80.8  55.0  25.8      10.8     18.777778\n",
      "2   20160603  68.4  77.9  55.6  22.3      12.8     20.222222\n",
      "13  20160614  59.7  67.8  47.8  20.0      11.9     15.388889\n",
      "14  20160615  63.4  70.3  49.3  21.0      14.1     17.444444\n",
      "16  20160617  60.4  70.7  55.9  14.8       4.5     15.777778\n",
      "19  20160620  59.3  69.1  52.2  16.9       7.1     15.166667\n",
      "20  20160621  62.6  71.4  50.4  21.0      12.2     17.000000\n",
      "21  20160622  61.7  70.2  55.4  14.8       6.3     16.500000\n",
      "22  20160623  60.9  67.1  54.9  12.2       6.0     16.055556\n",
      "23  20160624  61.1  68.9  56.7  12.2       4.4     16.166667\n",
      "24  20160625  65.7  75.4  57.9  17.5       7.8     18.722222\n",
      "25  20160626  69.6  77.7  60.3  17.4       9.3     20.888889\n",
      "26  20160627  60.7  70.0  57.6  12.4       3.1     15.944444\n",
      "27  20160628  65.4  73.0  55.8  17.2       9.6     18.555556\n",
      "28  20160629  65.8  73.2  59.7  13.5       6.1     18.777778\n",
      "29  20160630  65.7  72.7  59.2  13.5       6.5     18.722222\n"
     ]
    }
   ],
   "source": [
    "# Select rows with temp celsius higher than 15 degrees\n",
    "w_temps = dataFrame.loc[dataFrame['TEMP_Celsius'] > 15]\n",
    "print(w_temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, it is possible to combine multiple criteria at the same time. Below, we select temperatures above 15 degrees (i.e. `TEMP_Celsius` > 15) during the second half of June 2016 (i.e. ``YEARMODA >= 20160615``). For that, **the ``&`` operator (AND) or ``|`` operator (OR) combine multiple criteria**. Note, that it may be useful (i.e. easier to read), if you put the different clauses inside parentheses ``()``, to visually separate them from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEARMODA  TEMP   MAX   MIN  DIFF  DIFF_Min  TEMP_Celsius\n",
      "14  20160615  63.4  70.3  49.3  21.0      14.1     17.444444\n",
      "16  20160617  60.4  70.7  55.9  14.8       4.5     15.777778\n",
      "19  20160620  59.3  69.1  52.2  16.9       7.1     15.166667\n",
      "20  20160621  62.6  71.4  50.4  21.0      12.2     17.000000\n",
      "21  20160622  61.7  70.2  55.4  14.8       6.3     16.500000\n",
      "22  20160623  60.9  67.1  54.9  12.2       6.0     16.055556\n",
      "23  20160624  61.1  68.9  56.7  12.2       4.4     16.166667\n",
      "24  20160625  65.7  75.4  57.9  17.5       7.8     18.722222\n",
      "25  20160626  69.6  77.7  60.3  17.4       9.3     20.888889\n",
      "26  20160627  60.7  70.0  57.6  12.4       3.1     15.944444\n",
      "27  20160628  65.4  73.0  55.8  17.2       9.6     18.555556\n",
      "28  20160629  65.8  73.2  59.7  13.5       6.1     18.777778\n",
      "29  20160630  65.7  72.7  59.2  13.5       6.5     18.722222\n"
     ]
    }
   ],
   "source": [
    "# Select rows with temp celsius higher than 15 degrees from late June 2016\n",
    "w_temps2 = dataFrame.loc[(dataFrame['TEMP_Celsius'] > 15) & (dataFrame['YEARMODA'] >= 20160615)]\n",
    "print(w_temps2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a subset of our DataFrame that contains only rows with ``TEMP_Celsius`` above 15 and in which the dates in ``YEARMODA`` column start from 15th of June.\n",
    "\n",
    "If you inspect the results above, you may have noticed that the index values (numbers to the left) are still showing the rows positions from the original DataFrame. It is possible to **reset the index of the DataFrame using the ``reset_index()`` function**. \n",
    "\n",
    "By default, the ``reset_index()`` makes a new column called ``index`` to keep track of the previous indicees, which might be useful in some cases. However, here we want to omit the old row numbers, which we can command by passing the **parameter ``drop=True``**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEARMODA  TEMP   MAX   MIN  DIFF  DIFF_Min  TEMP_Celsius\n",
      "0   20160615  63.4  70.3  49.3  21.0      14.1     17.444444\n",
      "1   20160617  60.4  70.7  55.9  14.8       4.5     15.777778\n",
      "2   20160620  59.3  69.1  52.2  16.9       7.1     15.166667\n",
      "3   20160621  62.6  71.4  50.4  21.0      12.2     17.000000\n",
      "4   20160622  61.7  70.2  55.4  14.8       6.3     16.500000\n",
      "5   20160623  60.9  67.1  54.9  12.2       6.0     16.055556\n",
      "6   20160624  61.1  68.9  56.7  12.2       4.4     16.166667\n",
      "7   20160625  65.7  75.4  57.9  17.5       7.8     18.722222\n",
      "8   20160626  69.6  77.7  60.3  17.4       9.3     20.888889\n",
      "9   20160627  60.7  70.0  57.6  12.4       3.1     15.944444\n",
      "10  20160628  65.4  73.0  55.8  17.2       9.6     18.555556\n",
      "11  20160629  65.8  73.2  59.7  13.5       6.1     18.777778\n",
      "12  20160630  65.7  72.7  59.2  13.5       6.5     18.722222\n"
     ]
    }
   ],
   "source": [
    "# Reset index\n",
    "w_temps2 = w_temps2.reset_index(drop=True)\n",
    "print(w_temps2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the reset DataFrame above, the index values count from 0 to 12.\n",
    "\n",
    "## Dealing with missing data\n",
    "\n",
    "In this section, we want to discuss how to deal with missing data. To be able to illustrate that, we have to manipulate our DataFrame `w_temps` and create some missing data, first. Let's change the top five values of ``TEMP_Celsius`` to ``NaN`` (not-a-number), which we can achieve by ``loc[]`` indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEARMODA  TEMP   MAX   MIN  DIFF  DIFF_Min  TEMP_Celsius\n",
      "0   20160615  63.4  70.3  49.3  21.0      14.1           NaN\n",
      "1   20160617  60.4  70.7  55.9  14.8       4.5           NaN\n",
      "2   20160620  59.3  69.1  52.2  16.9       7.1           NaN\n",
      "3   20160621  62.6  71.4  50.4  21.0      12.2           NaN\n",
      "4   20160622  61.7  70.2  55.4  14.8       6.3           NaN\n",
      "5   20160623  60.9  67.1  54.9  12.2       6.0     16.055556\n",
      "6   20160624  61.1  68.9  56.7  12.2       4.4     16.166667\n",
      "7   20160625  65.7  75.4  57.9  17.5       7.8     18.722222\n",
      "8   20160626  69.6  77.7  60.3  17.4       9.3     20.888889\n",
      "9   20160627  60.7  70.0  57.6  12.4       3.1     15.944444\n",
      "10  20160628  65.4  73.0  55.8  17.2       9.6     18.555556\n",
      "11  20160629  65.8  73.2  59.7  13.5       6.1     18.777778\n",
      "12  20160630  65.7  72.7  59.2  13.5       6.5     18.722222\n"
     ]
    }
   ],
   "source": [
    "# Set temp_celsius as none in the first five rows\n",
    "w_temps2.loc[:4, 'TEMP_Celsius'] = None\n",
    "print(w_temps2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the manipulated DataFrame contains exactly five missing values at the top of the column `TEMP_Celsius`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Note:**\n",
    "\n",
    "You don't need to specify the starting index if you select data from the beginning of the DataFrame (at index 0). In this case, you can leave it empty, which works congruent to list indexing.\n",
    "\n",
    "</div>\n",
    "\n",
    "Missing data are very common in data sets, and typically you want make sure to to deal with them somehow. Common procedures to deal with `NaN`-values is to either **remove** them from\n",
    "the DataFrame or to **fill** them with some value. In Pandas both of these options are available and easy to perform.\n",
    "\n",
    "First, let's **clean the data by removing entries with `NaN`-values using the ``dropna()`` function**. The function accepts a ``subset`` parameter, which is a list of column names. These numbers provide the function with information, which columns should be searched for `NaN` values. Let's look at an example for the DataFrame `w_temps2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEARMODA  TEMP   MAX   MIN  DIFF  DIFF_Min  TEMP_Celsius\n",
      "5   20160623  60.9  67.1  54.9  12.2       6.0     16.055556\n",
      "6   20160624  61.1  68.9  56.7  12.2       4.4     16.166667\n",
      "7   20160625  65.7  75.4  57.9  17.5       7.8     18.722222\n",
      "8   20160626  69.6  77.7  60.3  17.4       9.3     20.888889\n",
      "9   20160627  60.7  70.0  57.6  12.4       3.1     15.944444\n",
      "10  20160628  65.4  73.0  55.8  17.2       9.6     18.555556\n",
      "11  20160629  65.8  73.2  59.7  13.5       6.1     18.777778\n",
      "12  20160630  65.7  72.7  59.2  13.5       6.5     18.722222\n"
     ]
    }
   ],
   "source": [
    "# Drop no data values based on temp_celsius column\n",
    "w_temps_clean = w_temps2.dropna(subset=['TEMP_Celsius'])\n",
    "\n",
    "print(w_temps_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As result, we get a DataFrame without the table rows that contained `NaN` values.\n",
    "\n",
    "Now, let's look at the alternative option for cleaning the data. You can **fill the `NaN` values using the ``fillna()``-function**. In the example below, we will fill them with the value 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEARMODA  TEMP   MAX   MIN  DIFF  DIFF_Min  TEMP_Celsius\n",
      "0   20160615  63.4  70.3  49.3  21.0      14.1      0.000000\n",
      "1   20160617  60.4  70.7  55.9  14.8       4.5      0.000000\n",
      "2   20160620  59.3  69.1  52.2  16.9       7.1      0.000000\n",
      "3   20160621  62.6  71.4  50.4  21.0      12.2      0.000000\n",
      "4   20160622  61.7  70.2  55.4  14.8       6.3      0.000000\n",
      "5   20160623  60.9  67.1  54.9  12.2       6.0     16.055556\n",
      "6   20160624  61.1  68.9  56.7  12.2       4.4     16.166667\n",
      "7   20160625  65.7  75.4  57.9  17.5       7.8     18.722222\n",
      "8   20160626  69.6  77.7  60.3  17.4       9.3     20.888889\n",
      "9   20160627  60.7  70.0  57.6  12.4       3.1     15.944444\n",
      "10  20160628  65.4  73.0  55.8  17.2       9.6     18.555556\n",
      "11  20160629  65.8  73.2  59.7  13.5       6.1     18.777778\n",
      "12  20160630  65.7  72.7  59.2  13.5       6.5     18.722222\n"
     ]
    }
   ],
   "source": [
    "# Fill na values with 0\n",
    "w_temps_na_filled = w_temps2.fillna(0)\n",
    "\n",
    "print(w_temps_na_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As result, we get a DataFrame where `NaN`-values are replaced by the value 0.00000.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Warning:** In many cases filling the data with a specific value can hamper with your data analysis, because you basically enter artificial data values. This can affect the results of your (e.g. statistical) analysis. In the example, the mean Celsius temperature in the DataFrame will have changed significantly, because the 0 values are decreasing the average temperature of the month. Therefore, removing `NaN`-values is usually preferred over filling them. But if filling is used, it should be done and evaluated carefully.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting data\n",
    "\n",
    "At some point, it might be neccessary to **sort your data in either descending or ascending order** based on values in a column. In Pandas this is done using the ``sort_values(by='YourColumnName')``-function. Let's sort the values of our entire `dataFrame` table based on the ``TEMP`` column and in ascending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEARMODA  TEMP   MAX   MIN  DIFF  DIFF_Min  TEMP_Celsius\n",
      "8   20160609  49.4  54.1  45.7   8.4       3.7      9.666667\n",
      "9   20160610  49.5  55.9  43.0  12.9       6.5      9.722222\n",
      "4   20160605  51.4  58.3  43.2  15.1       8.2     10.777778\n",
      "5   20160606  52.2  59.7  42.8  16.9       9.4     11.222222\n",
      "10  20160611  54.0  62.1  41.7  20.4      12.3     12.222222\n",
      "7   20160608  54.2  60.4  47.5  12.9       6.7     12.333333\n",
      "11  20160612  55.4  64.2  46.0  18.2       9.4     13.000000\n",
      "18  20160619  56.3  59.2  54.1   5.1       2.2     13.500000\n",
      "6   20160607  56.9  65.1  45.9  19.2      11.0     13.833333\n",
      "17  20160618  57.3  62.8  54.0   8.8       3.3     14.055556\n",
      "3   20160604  57.5  70.9  47.3  23.6      10.2     14.166667\n",
      "15  20160616  57.8  67.5  55.6  11.9       2.2     14.333333\n",
      "12  20160613  58.3  68.2  47.3  20.9      11.0     14.611111\n",
      "19  20160620  59.3  69.1  52.2  16.9       7.1     15.166667\n",
      "13  20160614  59.7  67.8  47.8  20.0      11.9     15.388889\n",
      "16  20160617  60.4  70.7  55.9  14.8       4.5     15.777778\n",
      "26  20160627  60.7  70.0  57.6  12.4       3.1     15.944444\n",
      "22  20160623  60.9  67.1  54.9  12.2       6.0     16.055556\n",
      "23  20160624  61.1  68.9  56.7  12.2       4.4     16.166667\n",
      "21  20160622  61.7  70.2  55.4  14.8       6.3     16.500000\n",
      "20  20160621  62.6  71.4  50.4  21.0      12.2     17.000000\n",
      "14  20160615  63.4  70.3  49.3  21.0      14.1     17.444444\n",
      "27  20160628  65.4  73.0  55.8  17.2       9.6     18.555556\n",
      "0   20160601  65.5  73.6  54.7  18.9      10.8     18.611111\n",
      "24  20160625  65.7  75.4  57.9  17.5       7.8     18.722222\n",
      "29  20160630  65.7  72.7  59.2  13.5       6.5     18.722222\n",
      "1   20160602  65.8  80.8  55.0  25.8      10.8     18.777778\n",
      "28  20160629  65.8  73.2  59.7  13.5       6.1     18.777778\n",
      "2   20160603  68.4  77.9  55.6  22.3      12.8     20.222222\n",
      "25  20160626  69.6  77.7  60.3  17.4       9.3     20.888889\n"
     ]
    }
   ],
   "source": [
    "# Sort dataframe, ascending\n",
    "sorted_temp_a = dataFrame.sort_values(by='TEMP')\n",
    "\n",
    "print(sorted_temp_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, it is also possible to sort them in descending order, which is achieved using the ``ascending=False`` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEARMODA  TEMP   MAX   MIN  DIFF  DIFF_Min  TEMP_Celsius\n",
      "25  20160626  69.6  77.7  60.3  17.4       9.3     20.888889\n",
      "2   20160603  68.4  77.9  55.6  22.3      12.8     20.222222\n",
      "1   20160602  65.8  80.8  55.0  25.8      10.8     18.777778\n",
      "28  20160629  65.8  73.2  59.7  13.5       6.1     18.777778\n",
      "29  20160630  65.7  72.7  59.2  13.5       6.5     18.722222\n",
      "24  20160625  65.7  75.4  57.9  17.5       7.8     18.722222\n",
      "0   20160601  65.5  73.6  54.7  18.9      10.8     18.611111\n",
      "27  20160628  65.4  73.0  55.8  17.2       9.6     18.555556\n",
      "14  20160615  63.4  70.3  49.3  21.0      14.1     17.444444\n",
      "20  20160621  62.6  71.4  50.4  21.0      12.2     17.000000\n",
      "21  20160622  61.7  70.2  55.4  14.8       6.3     16.500000\n",
      "23  20160624  61.1  68.9  56.7  12.2       4.4     16.166667\n",
      "22  20160623  60.9  67.1  54.9  12.2       6.0     16.055556\n",
      "26  20160627  60.7  70.0  57.6  12.4       3.1     15.944444\n",
      "16  20160617  60.4  70.7  55.9  14.8       4.5     15.777778\n",
      "13  20160614  59.7  67.8  47.8  20.0      11.9     15.388889\n",
      "19  20160620  59.3  69.1  52.2  16.9       7.1     15.166667\n",
      "12  20160613  58.3  68.2  47.3  20.9      11.0     14.611111\n",
      "15  20160616  57.8  67.5  55.6  11.9       2.2     14.333333\n",
      "3   20160604  57.5  70.9  47.3  23.6      10.2     14.166667\n",
      "17  20160618  57.3  62.8  54.0   8.8       3.3     14.055556\n",
      "6   20160607  56.9  65.1  45.9  19.2      11.0     13.833333\n",
      "18  20160619  56.3  59.2  54.1   5.1       2.2     13.500000\n",
      "11  20160612  55.4  64.2  46.0  18.2       9.4     13.000000\n",
      "7   20160608  54.2  60.4  47.5  12.9       6.7     12.333333\n",
      "10  20160611  54.0  62.1  41.7  20.4      12.3     12.222222\n",
      "5   20160606  52.2  59.7  42.8  16.9       9.4     11.222222\n",
      "4   20160605  51.4  58.3  43.2  15.1       8.2     10.777778\n",
      "9   20160610  49.5  55.9  43.0  12.9       6.5      9.722222\n",
      "8   20160609  49.4  54.1  45.7   8.4       3.7      9.666667\n"
     ]
    }
   ],
   "source": [
    "# Sort dataframe, descending\n",
    "sorted_temp_d = dataFrame.sort_values(by='TEMP', ascending=False)\n",
    "print(sorted_temp_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rounding and finding unique values\n",
    "\n",
    "Numeric values can be **round using the ``round()``-function**. Below, we round the Celsius temperatures to 0-decimals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEARMODA  TEMP   MAX   MIN  DIFF  DIFF_Min  TEMP_Celsius  Celsius_rounded\n",
      "0   20160601  65.5  73.6  54.7  18.9      10.8     18.611111             19.0\n",
      "1   20160602  65.8  80.8  55.0  25.8      10.8     18.777778             19.0\n",
      "2   20160603  68.4  77.9  55.6  22.3      12.8     20.222222             20.0\n",
      "3   20160604  57.5  70.9  47.3  23.6      10.2     14.166667             14.0\n",
      "4   20160605  51.4  58.3  43.2  15.1       8.2     10.777778             11.0\n",
      "5   20160606  52.2  59.7  42.8  16.9       9.4     11.222222             11.0\n",
      "6   20160607  56.9  65.1  45.9  19.2      11.0     13.833333             14.0\n",
      "7   20160608  54.2  60.4  47.5  12.9       6.7     12.333333             12.0\n",
      "8   20160609  49.4  54.1  45.7   8.4       3.7      9.666667             10.0\n",
      "9   20160610  49.5  55.9  43.0  12.9       6.5      9.722222             10.0\n",
      "10  20160611  54.0  62.1  41.7  20.4      12.3     12.222222             12.0\n",
      "11  20160612  55.4  64.2  46.0  18.2       9.4     13.000000             13.0\n",
      "12  20160613  58.3  68.2  47.3  20.9      11.0     14.611111             15.0\n",
      "13  20160614  59.7  67.8  47.8  20.0      11.9     15.388889             15.0\n",
      "14  20160615  63.4  70.3  49.3  21.0      14.1     17.444444             17.0\n",
      "15  20160616  57.8  67.5  55.6  11.9       2.2     14.333333             14.0\n",
      "16  20160617  60.4  70.7  55.9  14.8       4.5     15.777778             16.0\n",
      "17  20160618  57.3  62.8  54.0   8.8       3.3     14.055556             14.0\n",
      "18  20160619  56.3  59.2  54.1   5.1       2.2     13.500000             13.0\n",
      "19  20160620  59.3  69.1  52.2  16.9       7.1     15.166667             15.0\n",
      "20  20160621  62.6  71.4  50.4  21.0      12.2     17.000000             17.0\n",
      "21  20160622  61.7  70.2  55.4  14.8       6.3     16.500000             16.0\n",
      "22  20160623  60.9  67.1  54.9  12.2       6.0     16.055556             16.0\n",
      "23  20160624  61.1  68.9  56.7  12.2       4.4     16.166667             16.0\n",
      "24  20160625  65.7  75.4  57.9  17.5       7.8     18.722222             19.0\n",
      "25  20160626  69.6  77.7  60.3  17.4       9.3     20.888889             21.0\n",
      "26  20160627  60.7  70.0  57.6  12.4       3.1     15.944444             16.0\n",
      "27  20160628  65.4  73.0  55.8  17.2       9.6     18.555556             19.0\n",
      "28  20160629  65.8  73.2  59.7  13.5       6.1     18.777778             19.0\n",
      "29  20160630  65.7  72.7  59.2  13.5       6.5     18.722222             19.0\n"
     ]
    }
   ],
   "source": [
    "# Create new column, and round celsius values\n",
    "dataFrame['Celsius_rounded'] = dataFrame['TEMP_Celsius'].round(0)\n",
    "print(dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it might be useful to **extract unique values from a column**.\n",
    "This can be achived through the function ``unique_values()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19., 20., 14., 11., 12., 10., 13., 15., 17., 16., 21.])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique celsius values\n",
    "unique = dataFrame['Celsius_rounded'].unique()\n",
    "unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As result, we receive a **numpy array** of unique values in the column `'Celsius_rounded'`.\n",
    "\n",
    "**Note:** If your array of unique values is very long, you might not be able see all of them, as IPython collapses them. To circumvent that, print them as a list using the NumPy method `tolist()`. For that we have to import the NumPy module!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.0, 20.0, 14.0, 11.0, 12.0, 10.0, 13.0, 15.0, 17.0, 16.0, 21.0]\n"
     ]
    }
   ],
   "source": [
    "# unique values as list\n",
    "import numpy\n",
    "print(unique.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check: **How many days did we have unique mean temperature in June 2016?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 11 days with unique mean temperatures in June 2016.\n"
     ]
    }
   ],
   "source": [
    "# Number of unique values\n",
    "uniq_temp_days = len(unique)\n",
    "print(\"There were\", uniq_temp_days, \"days with unique mean temperatures in June 2016.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing data\n",
    "\n",
    "At last, we want to write the analyzed data into a file on our JupyterHub. For that, Pandas supports many different data formats by default (see the list at the top of this notebook).\n",
    "By far the most typical output format is a **CSV-file** and the function **``to_csv()``** can be used to save your data in this format. \n",
    "\n",
    "Let's save the data in `dataFrame` into a file of the name `Kumpula_temp_results_June_2016.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output filename\n",
    "output_fp = \"Kumpula_temps_June_2016.csv\"\n",
    "\n",
    "# Save dataframe to csv\n",
    "dataFrame.to_csv(output_fp, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only one Pandas statement, we have saved the data from our DataFrame to a file. If you open the file in the in the text editor of the JupyterHub (which should locate in the folder `assignments_M6`), you should see the following:\n",
    "\n",
    "<img src=\"./img/M64_KumpulaResultsFile_editor.png\" width=\"600\" />\n",
    "\n",
    "The first line contains the column names from our variable `dataFrame`. And the first entries on each further line in the datafile provide the index values for each data row. \n",
    "\n",
    "You can also see, that the numeric values in about the last four data columns contain quite many decimals. So, for our next file export, of the DataFrame ``w_temps``, we want to change the out put a bit. Let's reduce the precision of the numberic output to 1 decimal and save the temperature values without the index in the file `Kumpula_temps_above15_June_2016.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fp2 = \"Kumpula_temps_above15_June_2016.csv\"\n",
    "w_temps.to_csv(output_fp2, sep=',', index=False, float_format=\"%.1f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have **ommitted the index with setting the index parameter to false: ``index=False``**. And the **``float_format`` parameter can control the number of decimals to be written**, for that the text ``%.1f`` informs the function to write all columns with 1 decimal to the file (changing the value 1 to 2 would write 2 decimals etc.)\n",
    "\n",
    "<img src=\"./img/M64_KumpulaResultsFile2_editor.png\" width=\"400\" />\n",
    "\n",
    "This results in a \"cleaner\" output file, without the index column, and with only 1 decimal for floating point numbers.\n",
    "\n",
    "### DATAFRAME TO EXCEL, PLEASE?\n",
    "\n",
    "It is quite common to deliver data in MS Excel-format. Saving a DataFrame into an Excel-format is straightforward in Pandas. For that, we need to initialize a specific ``ExcelWriter`` object, and then we can specify the filename and the name for the spreadsheet, where the data should be stored. At last, the writer has to be instructed to create and save the output file. You could also omit the index and specify the float formatting as in our previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify output filename\n",
    "excel_output_fp = \"Kumpula_temps_above15_June_2016.xlsx\"\n",
    "\n",
    "# Initialize ExcelWriter\n",
    "writer = pd.ExcelWriter(excel_output_fp)\n",
    "\n",
    "# Write data to the ExcelWriter\n",
    "w_temps.to_excel(writer, sheet_name=\"Kumpula_temperatures\", index=False, float_format=\"%.1f\")\n",
    "\n",
    "# Save the data to the file\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you should have the Exce-file in your working directory `asssignments_M6`. You cannot open .xlsx files on the JupyterHub, but you could download it to your comptuer and open it there, to see the file content like this:\n",
    "\n",
    "<img src=\"./img/M64_KumpulaResultsFile_excel.png\" width=\"600\" />\n",
    "\n",
    "Note the data format and the correct naming of the spreadsheet in the screenshot of the Excel-file above.\n",
    "\n",
    "That's it for this lesson. Next, you should continue with an assignment exercise on Pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
