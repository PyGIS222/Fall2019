{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PyGIS222/Fall2019/blob/master/LessonM44_numpy.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Lesson 4.4\n",
    "\n",
    "# NumPy\n",
    "\n",
    "This Jupyter Notebook is part of module 4 of the course GIS222 (Fall2019). Carefully study the content of this Notebook and use the chance to reflect the material through the interactive examples.\n",
    "\n",
    "### Sources\n",
    "This notebook is an adapted version of the [NumPy components of Lessons 5 of the Geo-Python 2018](https://geo-python.github.io/site/2018/lessons/L5/numpy.html), which is licensed under a Creative Commons Attribution-ShareAlike 4.0 International licence. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {
    "numpy_logo.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Exploring Data with NumPy\n",
    "\n",
    "This lesson discusses [**NumPy**](http://www.numpy.org/), an important and sophisticated Python module to read, explore and process data files. \n",
    "\n",
    "![numpy_logo.png](attachment:numpy_logo.png)\n",
    "\n",
    "Reading data files using NumPy will make life a bit easier compared to the traditional Python way of reading data files.\n",
    "If you're curious about that, you can check out some of the lesson materials from past years about [reading data in the Pythonic way](https://geo-python.github.io/2017/lessons/L5/reading-data-from-file.html).\n",
    "\n",
    "## What is NumPy?\n",
    "NumPy is a library for Python designed for efficient scientific (numerical) computing.\n",
    "It is an essential library in Python that is used under the hood in many other modules (including [Matplotlib](https://matplotlib.org/) and [Pandas](https://pandas.pydata.org/)).\n",
    "Here, you will get a sense of a few things NumPy can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a data file with NumPy\n",
    "\n",
    "### Importing NumPy\n",
    "\n",
    "Now we're ready to read in our temperature data file.\n",
    "First, we need to import the NumPy module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it!\n",
    "NumPy is now ready to use.\n",
    "Notice that we have imported the NumPy module with the name `np`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a data file\n",
    "\n",
    "Now we'll read the file data into a variable called `data`.\n",
    "We can start by defining the location (filepath) of the data file in the variable `fp`. In this case, the file is located in a subdirectory of this notebook's (`assignments_M4`) folder: `./data/`. Hence, the combined file path and name are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = './data/Kumpula-June-2016-w-metadata.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read the file using the NumPy `genfromtxt()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.genfromtxt()` is a general function for reading data files separated by commas, spaces, or other common separators.\n",
    "For a full list of parameters for this function, please refer to the [NumPy documentation for numpy.genfromtxt()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html).\n",
    "\n",
    "Here we use the function simply by giving the filename as an input parameter.\n",
    "If all goes as planned, you should now have a new variable defined as `data` in memory that contains the contents of the data file.\n",
    "You can check the the contents of this variable by typing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting our data file\n",
    "\n",
    "Hmm...something doesn't look right here.\n",
    "You were perhaps expecting some temperature data, right?\n",
    "Instead we have only a list of `nan` values.\n",
    "\n",
    "`nan` stands for \"not a number\", and might indicate some problem with reading in the contents of the file.\n",
    "Looks like we need to investigate this further.\n",
    "\n",
    "We can begin our investigation by opening the data file in the JupyterHub file browser: simply click on the `Kumpula-June-2016-w-metadata.txt` data file. For that, you have to click on data folder in the current assignment folder, then click on the file.\n",
    "\n",
    "<img src=\"./img/M44_findDataFile.png\" title=\"Finding the datafile Kumpula-June-2016-w-metadata.txt in the directory assignments_M4b/data on the JupyterHub.\" width=\"500\" />\n",
    "\n",
    "Figure 1: *Finding the datafile Kumpula-June-2016-w-metadata.txt in the directory assignments_M4b/data on the JupyterHub.*\n",
    "\n",
    "You should see something like the following:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Data file contents: Daily temperatures (mean, min, max) for Kumpula, Helsinki\n",
    "#                     for June 1-30, 2016\n",
    "# Data source: https://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND\n",
    "# Data processing: Extracted temperatures from raw data file, converted to\n",
    "#                  comma-separated format\n",
    "#\n",
    "# David Whipp - 02.10.2017\n",
    "\n",
    "YEARMODA,TEMP,MAX,MIN\n",
    "20160601,65.5,73.6,54.7\n",
    "20160602,65.8,80.8,55.0\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe a few important things:\n",
    "\n",
    "- There are some metadata at the top of the file (a *header*) that provide basic information about its contents and source.\n",
    "  This isn’t data we want to process, so we need to skip over that part of the file when we load it.\n",
    "    - We can skip the top header lines in the file using the `skip_header` parameter.\n",
    "- The values in the data file are separated by commas.\n",
    "    - We can specify the value separator using the `delimiter` parameter.\n",
    "- The top row of values below the header contains names of the column variables.\n",
    "    - We'll deal with those later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading our data file, round 2\n",
    "\n",
    "Let's try reading again with this information in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(fp, skip_header=9, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we now skip the header lines (first 9 lines) using `skip_header=9` and tell NumPy the files is comma-separated using `delimiter=','`.\n",
    "\n",
    "Let's print out the contents of `data` now and see how things look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0160601e+07 6.5500000e+01 7.3600000e+01 5.4700000e+01]\n",
      " [2.0160602e+07 6.5800000e+01 8.0800000e+01 5.5000000e+01]\n",
      " [2.0160603e+07 6.8400000e+01 7.7900000e+01 5.5600000e+01]\n",
      " [2.0160604e+07 5.7500000e+01 7.0900000e+01 4.7300000e+01]\n",
      " [2.0160605e+07 5.1400000e+01 5.8300000e+01 4.3200000e+01]\n",
      " [2.0160606e+07 5.2200000e+01 5.9700000e+01 4.2800000e+01]\n",
      " [2.0160607e+07 5.6900000e+01 6.5100000e+01 4.5900000e+01]\n",
      " [2.0160608e+07 5.4200000e+01 6.0400000e+01 4.7500000e+01]\n",
      " [2.0160609e+07 4.9400000e+01 5.4100000e+01 4.5700000e+01]\n",
      " [2.0160610e+07 4.9500000e+01 5.5900000e+01 4.3000000e+01]\n",
      " [2.0160611e+07 5.4000000e+01 6.2100000e+01 4.1700000e+01]\n",
      " [2.0160612e+07 5.5400000e+01 6.4200000e+01 4.6000000e+01]\n",
      " [2.0160613e+07 5.8300000e+01 6.8200000e+01 4.7300000e+01]\n",
      " [2.0160614e+07 5.9700000e+01 6.7800000e+01 4.7800000e+01]\n",
      " [2.0160615e+07 6.3400000e+01 7.0300000e+01 4.9300000e+01]\n",
      " [2.0160616e+07 5.7800000e+01 6.7500000e+01 5.5600000e+01]\n",
      " [2.0160617e+07 6.0400000e+01 7.0700000e+01 5.5900000e+01]\n",
      " [2.0160618e+07 5.7300000e+01 6.2800000e+01 5.4000000e+01]\n",
      " [2.0160619e+07 5.6300000e+01 5.9200000e+01 5.4100000e+01]\n",
      " [2.0160620e+07 5.9300000e+01 6.9100000e+01 5.2200000e+01]\n",
      " [2.0160621e+07 6.2600000e+01 7.1400000e+01 5.0400000e+01]\n",
      " [2.0160622e+07 6.1700000e+01 7.0200000e+01 5.5400000e+01]\n",
      " [2.0160623e+07 6.0900000e+01 6.7100000e+01 5.4900000e+01]\n",
      " [2.0160624e+07 6.1100000e+01 6.8900000e+01 5.6700000e+01]\n",
      " [2.0160625e+07 6.5700000e+01 7.5400000e+01 5.7900000e+01]\n",
      " [2.0160626e+07 6.9600000e+01 7.7700000e+01 6.0300000e+01]\n",
      " [2.0160627e+07 6.0700000e+01 7.0000000e+01 5.7600000e+01]\n",
      " [2.0160628e+07 6.5400000e+01 7.3000000e+01 5.5800000e+01]\n",
      " [2.0160629e+07 6.5800000e+01 7.3200000e+01 5.9700000e+01]\n",
      " [2.0160630e+07 6.5700000e+01 7.2700000e+01 5.9200000e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's more like it.\n",
    "\n",
    "OK, so let's review what just happened.\n",
    "Well, the file content was read into a variable `data`, which is a type of NumPy *n*-dimensional structure used for storing data like a matrix.\n",
    "\n",
    "What?!?\n",
    "\n",
    "Yeah, in our case we have a two dimensional data struture similar to a spreadsheet. Everything is together in a single large data structure at the moment, but we'll see later in the lesson how to divide up our data and make interacting with it easier.\n",
    "\n",
    "Now we can move on to exploring our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking data file formats\n",
    "\n",
    "The example above, trying to read a datafile with some header text (the metadata in this case), is *very* common.\n",
    "Reading data into NumPy is pretty easy, but it helps to have a sense of what the datafile looks like before you try to read it.\n",
    "The challenge can be that large datafiles might not nicely (or quickly) load into the JupyterHub editor, so it might be better to look at only the top 5-10 lines of the file rather than loading the entire thing.\n",
    "Fortunately, there are solutions to that problem.\n",
    "\n",
    "When you're trying to think over how to read in a data file you can take advantage of common command-line tools like **head**.\n",
    "**head** is a simple program to read lines from the start of a data file and print them to the screen.\n",
    "\n",
    "You can use **head** from the terminal of the JupyterHub by first opening a JupyterHub terminal from the JupyterHub menu bar (**New** -> **Terminal**).\n",
    "Once in the terminal, you can simply navigate to the directory containing your datafile (using the commands `pwd`, `cd <folder>` or `cd ..`). Once you are in the correct folder, type **head** followed by the file name:\n",
    "\n",
    "```bash\n",
    "$ head Kumpula-June-2016-w-metadata.txt\n",
    "```\n",
    "\n",
    "You will receive the following:\n",
    "\n",
    "```bash\n",
    "# Data file contents: Daily temperatures (mean, min, max) for Kumpula, Helsinki\n",
    "#                     for June 1-30, 2016\n",
    "# Data source: https://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND\n",
    "# Data processing: Extracted temperatures from raw data file, converted to\n",
    "#                  comma-separated format\n",
    "#\n",
    "# David Whipp - 02.10.2017\n",
    "\n",
    "YEARMODA,TEMP,MAX,MIN\n",
    "20160601,65.5,73.6,54.7\n",
    "```\n",
    "\n",
    "As you can see, **head** gives you the first 10 lines of the file by default.\n",
    "You can use the `-n` flag to get a larger or smaller number of lines.\n",
    "\n",
    "```bash\n",
    "$ head -n 3 Kumpula-June-2016-w-metadata.txt\n",
    "```\n",
    "\n",
    "This will print only the first three lines of the file:\n",
    "\n",
    "```bash\n",
    "# Data file contents: Daily temperatures (mean, min, max) for Kumpula, Helsinki\n",
    "#                     for June 1-30, 2016\n",
    "# Data source: https://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring our dataset\n",
    "\n",
    "So this is a big deal for us.\n",
    "We now have some basic Python skills and the ability to read in data from a file for processing.\n",
    "A normal first step when you load new data is to explore the dataset a bit to understand what is there and its format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the data array's object type\n",
    "\n",
    "Perhaps as a first step, we can check the object type of data we have in our NumPy array `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy arrays are of the object type *numpy.ndarray*. Yes, this is a completely new Python object type, specifically written for and unique to objects of the NumPy module. The NumPy *ndarray* is similar to Python lists, however, it should be understood more as data matrix, or more precise as an array of multiple dimensions. With that the arrays are specialized to process large and dense data sets. And they allows for easy implementation of sophisticated mathematical operations, including matrix operations.\n",
    "\n",
    "The arrays have some significant difference from lists:\n",
    "\n",
    "* The array elements explicitly allow multidimensionality,\n",
    "* they make mathematical matrix operations possible,\n",
    "* they are indexed by a tuple of nonnegative integers,\n",
    "* the data type inside the array (e.g. precision of numbers, strings) can be defined, however,\n",
    "* the data type is constrained to the same for all array elements.\n",
    "\n",
    "As listed, the array elements are constrained to a specific data type, however, the entire array can consist of different *data types*. Let's see what that means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the data array's data type\n",
    "\n",
    "Let’s now have a look at the data types in our ndarray.\n",
    "We can find this in the `dtype` attribute that is part of the ndarray data type, something that is known automatically for this kind of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the data are floating point values with 64-bit precision. Find an overview of all available ndarry object types at this page of the [NumPy User Guide](https://docs.scipy.org/doc/numpy/user/basics.types.html?highlight=object%20types)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note:**\n",
    "\n",
    "There are some exceptions, but normal NumPy arrays will all have the same data type.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the size of the dataset\n",
    "\n",
    "We can also check to see how many rows and columns we have in the dataset using the `shape` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 4)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see how there are 30 rows of data and 4 columns. Other attributes that can be requested are:\n",
    "\n",
    "|NumPy Attribute | Content | Example |\n",
    "| :-: | :- | :-: |\n",
    "|ndim | number of dimensions | 2 |\n",
    "|shape |size of each dimension |(2, 3) |  \n",
    "|size |total size of the array |6 |\n",
    "|dtype |data type of the array |float64 |\n",
    "|itemsize |size in bytes |8 |\n",
    "|nbytes |total size in bytes |(= size x itemsize)|32 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with our data - Index slicing\n",
    "\n",
    "Let's have another quick look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0160601e+07 6.5500000e+01 7.3600000e+01 5.4700000e+01]\n",
      " [2.0160602e+07 6.5800000e+01 8.0800000e+01 5.5000000e+01]\n",
      " [2.0160603e+07 6.8400000e+01 7.7900000e+01 5.5600000e+01]\n",
      " [2.0160604e+07 5.7500000e+01 7.0900000e+01 4.7300000e+01]\n",
      " [2.0160605e+07 5.1400000e+01 5.8300000e+01 4.3200000e+01]\n",
      " [2.0160606e+07 5.2200000e+01 5.9700000e+01 4.2800000e+01]\n",
      " [2.0160607e+07 5.6900000e+01 6.5100000e+01 4.5900000e+01]\n",
      " [2.0160608e+07 5.4200000e+01 6.0400000e+01 4.7500000e+01]\n",
      " [2.0160609e+07 4.9400000e+01 5.4100000e+01 4.5700000e+01]\n",
      " [2.0160610e+07 4.9500000e+01 5.5900000e+01 4.3000000e+01]\n",
      " [2.0160611e+07 5.4000000e+01 6.2100000e+01 4.1700000e+01]\n",
      " [2.0160612e+07 5.5400000e+01 6.4200000e+01 4.6000000e+01]\n",
      " [2.0160613e+07 5.8300000e+01 6.8200000e+01 4.7300000e+01]\n",
      " [2.0160614e+07 5.9700000e+01 6.7800000e+01 4.7800000e+01]\n",
      " [2.0160615e+07 6.3400000e+01 7.0300000e+01 4.9300000e+01]\n",
      " [2.0160616e+07 5.7800000e+01 6.7500000e+01 5.5600000e+01]\n",
      " [2.0160617e+07 6.0400000e+01 7.0700000e+01 5.5900000e+01]\n",
      " [2.0160618e+07 5.7300000e+01 6.2800000e+01 5.4000000e+01]\n",
      " [2.0160619e+07 5.6300000e+01 5.9200000e+01 5.4100000e+01]\n",
      " [2.0160620e+07 5.9300000e+01 6.9100000e+01 5.2200000e+01]\n",
      " [2.0160621e+07 6.2600000e+01 7.1400000e+01 5.0400000e+01]\n",
      " [2.0160622e+07 6.1700000e+01 7.0200000e+01 5.5400000e+01]\n",
      " [2.0160623e+07 6.0900000e+01 6.7100000e+01 5.4900000e+01]\n",
      " [2.0160624e+07 6.1100000e+01 6.8900000e+01 5.6700000e+01]\n",
      " [2.0160625e+07 6.5700000e+01 7.5400000e+01 5.7900000e+01]\n",
      " [2.0160626e+07 6.9600000e+01 7.7700000e+01 6.0300000e+01]\n",
      " [2.0160627e+07 6.0700000e+01 7.0000000e+01 5.7600000e+01]\n",
      " [2.0160628e+07 6.5400000e+01 7.3000000e+01 5.5800000e+01]\n",
      " [2.0160629e+07 6.5800000e+01 7.3200000e+01 5.9700000e+01]\n",
      " [2.0160630e+07 6.5700000e+01 7.2700000e+01 5.9200000e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is OK, but we can certainly make it easier to work with.\n",
    "We can start by slicing our data up into different columns and creating new variables with the column data.\n",
    "Slices from our array can be extracted using the *index values*.\n",
    "In our case, we have two indices in our 2D data structure.\n",
    "For example, the index values `[2,0]` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20160603.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... give us the value at row 2, column 0.\n",
    "\n",
    "We can also use ranges of rows and columns using the `:` character.\n",
    "For example, we could get the first 5 rows of values in column zero by typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20160601., 20160602., 20160603., 20160604., 20160605.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, right?\n",
    "\n",
    "In fact, we don't even necessarily need the lower bound for this slice of data because NumPy will assume it for us if we don't list it.\n",
    "Let's see another example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20160601., 20160602., 20160603., 20160604., 20160605.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the lower bound of the index range `0` is assumed and we get all rows up to (but not including) index `5`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing our data into columns\n",
    "\n",
    "Now let's use the ideas of index slicing to cut our 2D data into 4 separate columns that will be easier to work with.\n",
    "As you might recall from the header of the file, we have 4 data values: `YEARMODA`, `TEMP`, `MAX`, and `MIN`.\n",
    "We can exract all of the values from a given column by not listing and upper or lower bound for the index slice.\n",
    "For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20160601. 20160602. 20160603. 20160604. 20160605. 20160606. 20160607.\n",
      " 20160608. 20160609. 20160610. 20160611. 20160612. 20160613. 20160614.\n",
      " 20160615. 20160616. 20160617. 20160618. 20160619. 20160620. 20160621.\n",
      " 20160622. 20160623. 20160624. 20160625. 20160626. 20160627. 20160628.\n",
      " 20160629. 20160630.]\n"
     ]
    }
   ],
   "source": [
    "print(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, this looks promising.\n",
    "Let's quickly handle the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data[:, 1]\n",
    "temp_max = data[:, 2]\n",
    "temp_min = data[:, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 4 variables, one for each column in the data file.\n",
    "This should make life easier when we want to perform some calculations on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the data in the interpreter's memory\n",
    "\n",
    "We can see the types of data we have defined at this point, the variable names, and their types using IPython's **magic command** `%whos`. This is quite handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the namespace does not contain any more variables and we can start over.\n",
    "\n",
    "We will mention a few more magic commands like this along the way. **Magics** are specific to and provided by the IPython kernel, which runs in the background of Jupyter Notebooks. You can find more magic commands on the [Documentation pages of IPython](https://ipython.readthedocs.io/en/stable/interactive/magics.html). \n",
    "If you are interested to know how the IPython kernel and Jupyter Notebooks connect this page will be interesting: https://jupyter.readthedocs.io/en/latest/architecture/how_jupyter_ipython_work.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic data calculations in NumPy\n",
    "\n",
    "NumPy ndarrays have a set of attributes they know about themselves and methods they can use to make calculations using the data.\n",
    "Useful methods include `mean()`, `min()`, `max()`, and `std()` (the standard deviation).\n",
    "For example, we can easily find the mean temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.730000000000004\n"
     ]
    }
   ],
   "source": [
    "print(temp.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vast amount of methods and functions are provided, including `sum()`, `std()`, `var()`, `median()`, `percentile()`, `any()`, `all()`.\n",
    "You can find a comprehensive list at the [reference pages of numpy](https://docs.scipy.org/doc/numpy/reference/routines.html). The page also contains a quick search bar, where you can type in and search for any numpy method and get all the information to understand and use them. Take some minutes to investigate the purpose and sytax of at least three of those methods.\n",
    "\n",
    "### Data type conversions\n",
    "\n",
    "Lastly, we can convert our ndarray data from one data type to another using the `astype()` method.\n",
    "As we see in the output from `%whos` above, our `date` array contains `float64` data, but it was simply integer values in the data file.\n",
    "We can convert `date` to integers by typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = date.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20160601 20160602 20160603 20160604 20160605 20160606 20160607 20160608\n",
      " 20160609 20160610 20160611 20160612 20160613 20160614 20160615 20160616\n",
      " 20160617 20160618 20160619 20160620 20160621 20160622 20160623 20160624\n",
      " 20160625 20160626 20160627 20160628 20160629 20160630]\n"
     ]
    }
   ],
   "source": [
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see our dates as whole integer values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Processing data with NumPy\n",
    "\n",
    "Now you should know the basics of the data structures in NumPy and how to explore your data using some tools that are provided by NumPy.\n",
    "Next, we continue to explore some of the basic data operations that are regularly needed when doing data analysis.\n",
    "\n",
    "To have a clean start, let's first use the magic command `%reset` to clear the namespace. The parameter `-f` executes the magic command without prompt. (You would have to confirm this with entering a `y` into the prompt, if you use only `%reset`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if it worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now let's again import NumPy, read the same data as before, and sort it into column arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = './data/Kumpula-June-2016-w-metadata.txt'\n",
    "data = np.genfromtxt(fp, skip_header=9, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = data[:, 0]\n",
    "temp = data[:, 1]\n",
    "temp_max = data[:, 2]\n",
    "temp_min = data[:, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating with NumPy arrays\n",
    "\n",
    "One of the most common things to do in NumPy is to create new arrays based on calculations between different other arrays (columns).\n",
    "\n",
    "### Creating arrays\n",
    "\n",
    "Arrays can be created in several ways. If you have data already stored in list and you want to perform numpy array operations on it, you can simply convert the list into a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "anyList = [1.5, 2.7, 3, 4]\n",
    "anyArray = np.array(anyList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in a shorter version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5 2.7 3.  4. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anyArray = np.array([1.5, 2.7, 3, 4])\n",
    "print(anyArray)\n",
    "type(anyArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, keep in mind that the data type has to be the same for all array elements. If the list contains int and float numbers, all will be translated into a float datatype in the array (as in the example above for the last two elements in the array). However, if the list contains strings and numbers, all items will be converted to a string datatype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.1', '2', '3', 'four'], dtype='<U32')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1.1, 2, 3, 'four'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common approach is to create an array of zeros with the same length as other existing arrays.\n",
    "This can be thought of as a blank space for calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.zeros(len(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what just happened?\n",
    "We created a new array of zeros using the NumPy `zeros()` function, which takes the size of the array as a parameter.\n",
    "In our case, we've given the size to be the length of the `date` array.\n",
    "In other words, `len(date)`.\n",
    "\n",
    "There are many more NumPy functions that help to create different basic arrays:\n",
    "\n",
    "* numpy.**empty()**: \tuninitialized array of certain size\n",
    "* numpy.**ones()**: \tarray of certain size, filled with ones\n",
    "* numpy.**zeros()**: \tarray of certain size, filled with zeros\n",
    "* numpy.**full()**: \t\tarray of certain size, filled with a given number\n",
    "* numpy.**arrange()**: \tfill with linear sequence\n",
    "* numpy.**linspace()**: \tevenly spaced values in a range\n",
    "* numpy.**random()**: \trandom values, with various distributions\n",
    "* numpy.**eye()**:\t\tidentity matrix\n",
    "\n",
    "For example, to create an identity matrix of dimension 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(3)    # identity matrix of dimension 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment in the code cells below to practice using these functions. Refer to the [NumPy Reference Pages](https://docs.scipy.org/doc/numpy/reference/routines.html), if you want to know the exact syntax of using these functions. Or just try them first and then figure it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create different types of NumPy arrays with the commands above\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create different types of NumPy arrays with the commands above\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcuating values using other arrays\n",
    "\n",
    "Let's continue with the new `diff` array to calculate something useful, such as the difference between the `temp_max` and `temp_min` values for each row in our data.\n",
    "How do we do that?\n",
    "It's easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = temp_max - temp_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.9 25.8 22.3 23.6 15.1 16.9 19.2 12.9  8.4 12.9 20.4 18.2 20.9 20.\n",
      " 21.  11.9 14.8  8.8  5.1 16.9 21.  14.8 12.2 12.2 17.5 17.4 12.4 17.2\n",
      " 13.5 13.5]\n"
     ]
    }
   ],
   "source": [
    "print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simply subtract `temp_min` from `temp_max`. This ease of array operations is what NumPy is all about. (To doo this with lists, you would have to iterate over each element in loop statements.)\n",
    "\n",
    "In fact, we don't even need to create the array first.\n",
    "Let's consider another example of calculating the difference between the daily mean temperature and the minimum temperature.\n",
    "We can calculate that simply as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_min = temp - temp_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.8 10.8 12.8 10.2  8.2  9.4 11.   6.7  3.7  6.5 12.3  9.4 11.  11.9\n",
      " 14.1  2.2  4.5  3.3  2.2  7.1 12.2  6.3  6.   4.4  7.8  9.3  3.1  9.6\n",
      "  6.1  6.5]\n"
     ]
    }
   ],
   "source": [
    "print(diff_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we subtract one NumPy array from another, NumPy is smart enough to automatically create a new array to store the output.\n",
    "We can confirm this by checking the type of the `diff_min` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(diff_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one final example, let's consider converting temperatures in Fahrenheit to Celsius.\n",
    "We can store the results as `temp_celsius`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_celsius = (temp - 32) / (9/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.61111111 18.77777778 20.22222222 14.16666667 10.77777778 11.22222222\n",
      " 13.83333333 12.33333333  9.66666667  9.72222222 12.22222222 13.\n",
      " 14.61111111 15.38888889 17.44444444 14.33333333 15.77777778 14.05555556\n",
      " 13.5        15.16666667 17.         16.5        16.05555556 16.16666667\n",
      " 18.72222222 20.88888889 15.94444444 18.55555556 18.77777778 18.72222222]\n"
     ]
    }
   ],
   "source": [
    "print(temp_celsius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, since we use a NumPy ndarray in the calculation, a ndarray is output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering data\n",
    "\n",
    "Another common thing to do with data is to look for a subset of the data that match some criterion.\n",
    "For example, we might want to create an array called `w_temps` that contains \"warm\" temperatures, those above 15°C.\n",
    "We can do that as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_temps = temp_celsius[temp_celsius > 15.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.61111111 18.77777778 20.22222222 15.38888889 17.44444444 15.77777778\n",
      " 15.16666667 17.         16.5        16.05555556 16.16666667 18.72222222\n",
      " 20.88888889 15.94444444 18.55555556 18.77777778 18.72222222]\n"
     ]
    }
   ],
   "source": [
    "print(w_temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see only the temperatures above 15°C, as expected.\n",
    "\n",
    "It is also possible to combine multiple criteria at the same time.\n",
    "Here, we select temperatures above 15 degrees that were recorded in the second half of June in 2016 (i.e. `date >= 20160615`).\n",
    "Combining multiple criteria can be done with the `&` operator (logical AND) or the `|` operator (logical OR).\n",
    "Notice, that it is useful to separate the different clauses inside parentheses `()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_temps2 = temp_celsius[(temp_celsius > 15.0) & (date >= 20160615)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.44444444 15.77777778 15.16666667 17.         16.5        16.05555556\n",
      " 16.16666667 18.72222222 20.88888889 15.94444444 18.55555556 18.77777778\n",
      " 18.72222222]\n"
     ]
    }
   ],
   "source": [
    "print(w_temps2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With two constraints on the data, that `temp_celsius` must be greater that 15°C and `date` must be on or after June 15, 2016 (i.e., `20160615`), we get a smaller subset of the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data masks\n",
    "\n",
    "The filtering examples above are nice, but what if we would like to identify the dates with temperatures above 15°C and keep only those dates in our other data columns, such as `date`, `temp`, etc.\n",
    "How can we do that?\n",
    "\n",
    "In order to do that, we will need to use a *mask* array.\n",
    "A mask array is basically a boolean (True/False) array that can be used to take a subset of data from other arrays.\n",
    "Let's consider our example of warm temperatures once again.\n",
    "Rather than extracting `w_temps` directly, we can start by identifying the values in `temp_celsius` where the value is above 15°C (`True`) or less than or equal to 15°C (`False`).\n",
    "The logic is quite similar to before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_temps_mask = temp_celsius > 15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True False False False False False False False False False\n",
      " False  True  True False  True False False  True  True  True  True  True\n",
      "  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(w_temps_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see a list of `True` and `False` values in an array of the same size as `temp_celsius`.\n",
    "This array shows us whether the condition we stated is `True` or `False` for each index.\n",
    "\n",
    "Now, if we wanted to know the dates when the temperature was above 15°C, we can simply take the values from the `date` array using the mask we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_temp_dates = date[w_temps_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20160601. 20160602. 20160603. 20160614. 20160615. 20160617. 20160620.\n",
      " 20160621. 20160622. 20160623. 20160624. 20160625. 20160626. 20160627.\n",
      " 20160628. 20160629. 20160630.]\n"
     ]
    }
   ],
   "source": [
    "print(w_temp_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, right?\n",
    "Now we see only the subset of dates that match the condition of having a temperature above 15°C, and the lengths of `w_temps` and `w_temp_dates` are the same, meaning we know both the date that the temperature exceeded 15°C and the temperature itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w_temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w_temp_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing missing/bad data\n",
    "\n",
    "In some cases, a data file might contain missing values or values that cannot be read.\n",
    "These may be replaced by `nan` values when you look at your data.\n",
    "`nan` stands for \"not a number\", and often we want to get rid of these things.\n",
    "\n",
    "Let's consider a case where we have an array `bad_data` that is full of zeros, has the same size as `date` and the other arrays from our data file, and the first 5 rows have `nan` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_data = np.zeros(len(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_data[:5] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(bad_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the problem clearly.\n",
    "\n",
    "If we wanted to include values for the `date` column that only correspond to locations in `bad_data` where we do not have a `nan` value, we can use the `isfinite()` function in NumPy.\n",
    "`isfinite()` checks to see if a value is defined (i.e., is not `nan` or infinite (`inf`).\n",
    "Let's make a mask with `bad_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_data_mask = np.isfinite(bad_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(bad_data_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the expected results.\n",
    "If we want now to include only the dates with good data, we can use the mask as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_dates = date[bad_data_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20160606. 20160607. 20160608. 20160609. 20160610. 20160611. 20160612.\n",
      " 20160613. 20160614. 20160615. 20160616. 20160617. 20160618. 20160619.\n",
      " 20160620. 20160621. 20160622. 20160623. 20160624. 20160625. 20160626.\n",
      " 20160627. 20160628. 20160629. 20160630.]\n"
     ]
    }
   ],
   "source": [
    "print(good_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rounding and finding unique values\n",
    "\n",
    "It is possible to round values easily using the `round()` method for NumPy arrays.\n",
    "Let's round our temperatures in Celsius to zero decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_celsius_rounded = temp_celsius.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19. 19. 20. 14. 11. 11. 14. 12. 10. 10. 12. 13. 15. 15. 17. 14. 16. 14.\n",
      " 13. 15. 17. 16. 16. 16. 19. 21. 16. 19. 19. 19.]\n"
     ]
    }
   ],
   "source": [
    "print(temp_celsius_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding unique values\n",
    "\n",
    "We can find unique values in an array using the `unique()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = np.unique(temp_celsius_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10. 11. 12. 13. 14. 15. 16. 17. 19. 20. 21.]\n"
     ]
    }
   ],
   "source": [
    "print(unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do not see any repeated values in our rounded temperatures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further useful array operations\n",
    "\n",
    "#### Fancy indexing\n",
    "\n",
    "We can use fancy indexing, which allows quick access and modification of complicated subsets of an array. It works like simple indexing, but one passes arrays of indices in place of single scalars. For example, to get the first, third and ninth element in the variable `temp_celsius_rounded`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19. 20. 10.]\n"
     ]
    }
   ],
   "source": [
    "selecte_temps = temp_celsius_rounded[[0,2,8]]\n",
    "print(selecte_temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating (joining) arrays\n",
    "\n",
    "Arrays can also be concatenated or splitted, with the methods `np.concatenate()` and `np.split()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19. 20. 10. 19. 20. 10. 19. 20. 10.]\n"
     ]
    }
   ],
   "source": [
    "concat_temps = np.concatenate([selecte_temps,selecte_temps,selecte_temps])\n",
    "print(concat_temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19. 20. 10. 19.]\n",
      "[20. 10. 19. 20. 10.]\n"
     ]
    }
   ],
   "source": [
    "split_temps1, split_temps2 = np.split(concat_temps, [4])\n",
    "print(split_temps1)\n",
    "print(split_temps2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping of NumPy arrays\n",
    "\n",
    "Reshape array dimensions, the reshape() method is most flexible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9]\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.arange(1,10)\n",
    "x2 = x1.reshape((3,3)) \n",
    "print(x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving our data to a file\n",
    "\n",
    "Finally we can save our modified data to a file for future use.\n",
    "We'll need to do a few steps to get there, however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-creating our 2D data array\n",
    "\n",
    "As you have seen, we have mostly worked with single columns after reading in our data.\n",
    "We can recreate a 2D data structure by stacking these columns back together.\n",
    "\n",
    "For example, let's put together our `date`, `temp`, and `temp_celsius` columns in a new data array called `new_data`.\n",
    "We can start by stacking the data together using the `vstack()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = np.vstack((date, temp, temp_celsius))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.01606010e+07 2.01606020e+07 2.01606030e+07 2.01606040e+07\n",
      "  2.01606050e+07 2.01606060e+07 2.01606070e+07 2.01606080e+07\n",
      "  2.01606090e+07 2.01606100e+07 2.01606110e+07 2.01606120e+07\n",
      "  2.01606130e+07 2.01606140e+07 2.01606150e+07 2.01606160e+07\n",
      "  2.01606170e+07 2.01606180e+07 2.01606190e+07 2.01606200e+07\n",
      "  2.01606210e+07 2.01606220e+07 2.01606230e+07 2.01606240e+07\n",
      "  2.01606250e+07 2.01606260e+07 2.01606270e+07 2.01606280e+07\n",
      "  2.01606290e+07 2.01606300e+07]\n",
      " [6.55000000e+01 6.58000000e+01 6.84000000e+01 5.75000000e+01\n",
      "  5.14000000e+01 5.22000000e+01 5.69000000e+01 5.42000000e+01\n",
      "  4.94000000e+01 4.95000000e+01 5.40000000e+01 5.54000000e+01\n",
      "  5.83000000e+01 5.97000000e+01 6.34000000e+01 5.78000000e+01\n",
      "  6.04000000e+01 5.73000000e+01 5.63000000e+01 5.93000000e+01\n",
      "  6.26000000e+01 6.17000000e+01 6.09000000e+01 6.11000000e+01\n",
      "  6.57000000e+01 6.96000000e+01 6.07000000e+01 6.54000000e+01\n",
      "  6.58000000e+01 6.57000000e+01]\n",
      " [1.86111111e+01 1.87777778e+01 2.02222222e+01 1.41666667e+01\n",
      "  1.07777778e+01 1.12222222e+01 1.38333333e+01 1.23333333e+01\n",
      "  9.66666667e+00 9.72222222e+00 1.22222222e+01 1.30000000e+01\n",
      "  1.46111111e+01 1.53888889e+01 1.74444444e+01 1.43333333e+01\n",
      "  1.57777778e+01 1.40555556e+01 1.35000000e+01 1.51666667e+01\n",
      "  1.70000000e+01 1.65000000e+01 1.60555556e+01 1.61666667e+01\n",
      "  1.87222222e+01 2.08888889e+01 1.59444444e+01 1.85555556e+01\n",
      "  1.87777778e+01 1.87222222e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our data back in a single array, but something isn't quite right.\n",
    "The columns and rows need to be flipped.\n",
    "We can do this using the `transpose()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = np.transpose(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.01606010e+07 6.55000000e+01 1.86111111e+01]\n",
      " [2.01606020e+07 6.58000000e+01 1.87777778e+01]\n",
      " [2.01606030e+07 6.84000000e+01 2.02222222e+01]\n",
      " [2.01606040e+07 5.75000000e+01 1.41666667e+01]\n",
      " [2.01606050e+07 5.14000000e+01 1.07777778e+01]\n",
      " [2.01606060e+07 5.22000000e+01 1.12222222e+01]\n",
      " [2.01606070e+07 5.69000000e+01 1.38333333e+01]\n",
      " [2.01606080e+07 5.42000000e+01 1.23333333e+01]\n",
      " [2.01606090e+07 4.94000000e+01 9.66666667e+00]\n",
      " [2.01606100e+07 4.95000000e+01 9.72222222e+00]\n",
      " [2.01606110e+07 5.40000000e+01 1.22222222e+01]\n",
      " [2.01606120e+07 5.54000000e+01 1.30000000e+01]\n",
      " [2.01606130e+07 5.83000000e+01 1.46111111e+01]\n",
      " [2.01606140e+07 5.97000000e+01 1.53888889e+01]\n",
      " [2.01606150e+07 6.34000000e+01 1.74444444e+01]\n",
      " [2.01606160e+07 5.78000000e+01 1.43333333e+01]\n",
      " [2.01606170e+07 6.04000000e+01 1.57777778e+01]\n",
      " [2.01606180e+07 5.73000000e+01 1.40555556e+01]\n",
      " [2.01606190e+07 5.63000000e+01 1.35000000e+01]\n",
      " [2.01606200e+07 5.93000000e+01 1.51666667e+01]\n",
      " [2.01606210e+07 6.26000000e+01 1.70000000e+01]\n",
      " [2.01606220e+07 6.17000000e+01 1.65000000e+01]\n",
      " [2.01606230e+07 6.09000000e+01 1.60555556e+01]\n",
      " [2.01606240e+07 6.11000000e+01 1.61666667e+01]\n",
      " [2.01606250e+07 6.57000000e+01 1.87222222e+01]\n",
      " [2.01606260e+07 6.96000000e+01 2.08888889e+01]\n",
      " [2.01606270e+07 6.07000000e+01 1.59444444e+01]\n",
      " [2.01606280e+07 6.54000000e+01 1.85555556e+01]\n",
      " [2.01606290e+07 6.58000000e+01 1.87777778e+01]\n",
      " [2.01606300e+07 6.57000000e+01 1.87222222e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our data\n",
    "\n",
    "With the data in the correct format, we can now save it to a file using the `savetxt()` function.\n",
    "Let's save our data to a file called `converted_temps.csv`, where the `.csv` indicates the data values are separated by commas (comma-separated values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('converted_temps.csv', new_data, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool.\n",
    "We have now saved the array `new_data` to the file `converted_temps.csv` with commas between the values (using the `delimiter=','` parameter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Rules of Broadcasting: A Self study!\n",
    "\n",
    "\n",
    "\n",
    "NumPy's broadcasting functionality provides a way to perform arithmetic operations on arrays of different sizes (or dimensions). In other words, wroadcasting is simply a set of rules for applying binary ufuncs (e.g., addition, subtraction, multiplication, etc.) on arrays of different sizes.\n",
    "\n",
    "Find some breadcrumps on the topic below: a coding examples, some rules and an image. Perform a self-study to find out what these mean and how they relate to working with *ndarrays*. You can find details on this in the external the notebook [Computation on Arrays: Broadcasting](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html) from the Data Science Handbook of Jake VanderPlas (2017) as well as on the page [NumPy User Guide on Broadcasting](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html). \n",
    "\n",
    "**Make use of the option to add your own notes and examples belwo in markdown as well as code cells, for later reference.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a6984caa1669>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3]) \n",
    "b = np.array([[1, 2, 3], [4, 5, 6], [7 ,8, 9]])\n",
    "c = a * b \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Rules of Broadcasting**\n",
    "\n",
    "* **Rule 1**: If the two arrays differ in their number of dimensions, the shape of the one with fewer dimensions is padded with ones on its leading (left) side.\n",
    "* **Rule 2**: If the shape of the two arrays does not match in any dimension, the array with shape equal to 1 in that dimension is stretched to match the other shape.\n",
    "* **Rule 3**: If in any dimension the sizes disagree and neither is equal to 1, an error is raised.\n",
    "\n",
    "</div>\n",
    "\n",
    "<img src=\"./img/M44_rulesOfBroadcasting.png\" title=\"Rules of Broadcasting\" width=\"300\" />\n",
    "\n",
    "Figure 2: *Rules of Broadcasting*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further References\n",
    "\n",
    "* [NumPy](https://www.numpy.org): The package's official internet site.\n",
    "* [NumPy's Reference](https://docs.scipy.org/doc/numpy-1.13.0/reference/): Search any function to learn it's syntax\n",
    "* [NumPy's Quickstart Tutorial](https://numpy.org/devdocs/user/quickstart.html): A simple tutorial from NumPy on NumPy.\n",
    "* [NumPy's User Guide](https://docs.scipy.org/doc/numpy/user/): Some more resources to learning NumPy.\n",
    "* [Tutorialspoint NumPy Tutorial](https://www.tutorialspoint.com/numpy/index.htm): Systematic free tutorial on NumPy from Tutorialspoint."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
